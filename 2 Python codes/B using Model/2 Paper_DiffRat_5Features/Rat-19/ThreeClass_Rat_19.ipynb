{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5ca1b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def rdnumpy(txtname):\n",
    "    f = open(txtname)\n",
    "    line = f.readlines()\n",
    "    lines = len(line)  # row number\n",
    "    for l in line:\n",
    "        le = l.strip('\\n').split(',')\n",
    "        columns = len(le)-1  # col\n",
    "        #print(le)\n",
    "        #print(columns)\n",
    " \n",
    "    A = np.zeros((lines, columns+1), dtype=np.single)\n",
    "    print(\"read lines:\",lines)\n",
    "    print(\"read columns:\",columns+1)\n",
    "    A_row = 0\n",
    "    for lin in line:\n",
    "        #print(A_row)\n",
    "        list = lin.strip('\\n').split(',')\n",
    "        A[A_row:] = list[0:columns+1]\n",
    "        A_row += 1\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4a1d5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train &Test: 3360+1440"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1711e26",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85be43f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision.transforms import ToTensor, ToPILImage, Lambda\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "45a0dad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x21209c7e410>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 3\n",
    "batch_size_train = 6 #32,或者16-由於數據集比較小\n",
    "batch_size_test = 1440*3\n",
    "learning_rate = 0.001 #0.0001\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "random_seed = 1\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d53457b",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abfb5c5b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read lines: 3360\n",
      "read columns: 9\n",
      "read lines: 3360\n",
      "read columns: 9\n",
      "read lines: 3360\n",
      "read columns: 9\n"
     ]
    }
   ],
   "source": [
    "TrainDataf1=torch.as_tensor(rdnumpy(\"D:\\FYP-HPC\\Data_Python\\GCN_PAPER_DiffRat_6F_1s\\Rat19\\MTrainGf1.txt\"))\n",
    "TrainDataw0=torch.as_tensor(rdnumpy(\"D:\\FYP-HPC\\Data_Python\\GCN_PAPER_DiffRat_6F_1s\\Rat19\\MTrainGw0.txt\"))\n",
    "TrainDatam3=torch.as_tensor(rdnumpy(\"D:\\FYP-HPC\\Data_Python\\GCN_PAPER_DiffRat_6F_1s\\Rat19\\MTrainGm3.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6492c79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  0.1183,  0.0282,  0.7150,  0.0582,  0.3687, -1.2881, 15.0000],\n",
       "        [ 2.0000,  1.2780,  2.4357,  0.9571,  1.0776,  0.8969,  3.3460, 15.0000],\n",
       "        [ 3.0000,  1.1799,  3.1711,  0.9647,  0.8765,  0.8870, 21.6785, 15.0000],\n",
       "        [ 4.0000,  1.1765,  3.3322,  0.9584,  0.9050,  0.8870, 18.8320, 15.0000],\n",
       "        [ 5.0000,  1.2407,  2.1534,  0.9738,  0.9513,  0.9368,  3.2906, 15.0000],\n",
       "        [ 6.0000,  1.2150,  1.9671,  0.9528,  0.9086,  0.8969, -4.1514, 15.0000],\n",
       "        [ 7.0000,  1.2201,  2.6830,  0.9509,  0.9928,  0.8670,  4.6306, 15.0000],\n",
       "        [ 8.0000,  1.2198,  3.7038,  0.9554,  0.9882,  0.8969, 11.2714, 15.0000]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=1        \n",
    "startRow=i*8;\n",
    "enRow=(i+1)*8;\n",
    "TrainDataf1[startRow:enRow,1:9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd74d814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9b9ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4be7d9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScottTrainDataset(Dataset):\n",
    "    def __init__(self, transform=None, target_transform=None):\n",
    "        TrainDataf1=torch.as_tensor(rdnumpy(\"D:\\FYP-HPC\\Data_Python\\GCN_PAPER_DiffRat_6F_1s\\Rat19\\MTrainGf1.txt\"))\n",
    "        TrainDataw0=torch.as_tensor(rdnumpy(\"D:\\FYP-HPC\\Data_Python\\GCN_PAPER_DiffRat_6F_1s\\Rat19\\MTrainGw0.txt\"))\n",
    "        TrainDatam3=torch.as_tensor(rdnumpy(\"D:\\FYP-HPC\\Data_Python\\GCN_PAPER_DiffRat_6F_1s\\Rat19\\MTrainGm3.txt\"))\n",
    "        #TrainDataq4=torch.as_tensor(rdnumpy(\"D:\\FYP-HPC\\Data_Python\\GCN_PAPER_DiffRat_6F_1s\\Rat16\\MTrainGq4.txt\"))\n",
    "        \n",
    "        self.AllTrainData=torch.cat((TrainDataw0,TrainDataf1,TrainDatam3),0)\n",
    "        # 定义transform\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    " \n",
    "    def __len__(self):\n",
    "        '''返回数据集中的样本数'''\n",
    "        return 420*3\n",
    " \n",
    "    def __getitem__(self, index):#需要第index個的數據\n",
    "        '''获取数据的方法，会和Dataloader连用'''\n",
    "        i=index;        \n",
    "        startRow=i*8;\n",
    "        enRow=(i+1)*8;\n",
    "        nowData=self.AllTrainData[startRow:enRow,2:7]\n",
    "        \n",
    "        if index>=0 and index<420:\n",
    "            nowLabel=1\n",
    "        elif index>=420 and index<420*2:\n",
    "            nowLabel=0\n",
    "        elif index>=420*2 and index<420*3:\n",
    "            nowLabel=2\n",
    "            \n",
    "        if self.transform:\n",
    "            nowData = self.transform(nowData)\n",
    "        if self.target_transform:\n",
    "            nowLabel = self.target_transform(nowLabel)\n",
    "        '''\n",
    "        if nowLabel==0:\n",
    "            nowLabel = torch.FloatTensor([1, 0])\n",
    "        else:\n",
    "            nowLabel = torch.FloatTensor([0, 1])\n",
    "        '''\n",
    "        return nowData, nowLabel#需要返回數據和標簽"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64523fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScottTestDataset(Dataset):\n",
    "    def __init__(self, transform=None, target_transform=None):\n",
    "        TestDataf1=torch.as_tensor(rdnumpy(\"D:\\FYP-HPC\\Data_Python\\GCN_PAPER_DiffRat_6F_1s\\Rat19\\MTestGf1.txt\"))\n",
    "        TestDataw0=torch.as_tensor(rdnumpy(\"D:\\FYP-HPC\\Data_Python\\GCN_PAPER_DiffRat_6F_1s\\Rat19\\MTestGw0.txt\"))\n",
    "        TestDatam3=torch.as_tensor(rdnumpy(\"D:\\FYP-HPC\\Data_Python\\GCN_PAPER_DiffRat_6F_1s\\Rat19\\MTestGm3.txt\"))\n",
    "        #TestDataq4=torch.as_tensor(rdnumpy(\"D:\\FYP-HPC\\Data_Python\\GCN_PAPER_DiffRat_6F_1s\\Rat16\\MTestGq4.txt\"))\n",
    "        \n",
    "        self.AllTrainData=torch.cat((TestDataw0,TestDataf1,TestDatam3),0)\n",
    "        # 定义transform\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    " \n",
    "    def __len__(self):\n",
    "        '''返回数据集中的样本数'''\n",
    "        return 180*3\n",
    " \n",
    "    def __getitem__(self, index):#需要第index個的數據\n",
    "        '''获取数据的方法，会和Dataloader连用'''\n",
    "        i=index;        \n",
    "        startRow=i*8;\n",
    "        enRow=(i+1)*8;\n",
    "        nowData=self.AllTrainData[startRow:enRow,2:7]\n",
    "        \n",
    "        if index>=0 and index<180:\n",
    "            nowLabel=1\n",
    "        elif index>=180 and index<180*2:\n",
    "            nowLabel=0\n",
    "        elif index>=180*2 and index<180*3:\n",
    "            nowLabel=2\n",
    "            \n",
    "        if self.transform:\n",
    "            nowData = self.transform(nowData)\n",
    "        if self.target_transform:\n",
    "            nowLabel = self.target_transform(nowLabel)\n",
    "            \n",
    "        '''\n",
    "        if nowLabel==0:\n",
    "            nowLabel = torch.FloatTensor([1, 0])\n",
    "        else:\n",
    "            nowLabel = torch.FloatTensor([0, 1])\n",
    "        '''\n",
    "            \n",
    "        return nowData, nowLabel#需要返回數據和標簽"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a48a8959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read lines: 3360\n",
      "read columns: 9\n",
      "read lines: 3360\n",
      "read columns: 9\n",
      "read lines: 3360\n",
      "read columns: 9\n",
      "read lines: 1440\n",
      "read columns: 9\n",
      "read lines: 1440\n",
      "read columns: 9\n",
      "read lines: 1440\n",
      "read columns: 9\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(ScottTrainDataset(),\n",
    "    batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(ScottTestDataset(),\n",
    "    batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ba390d",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7a253c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://zhuanlan.zhihu.com/p/199624393\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(10,20, kernel_size=3, padding=1)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(40, 15)\n",
    "        self.fc2 = nn.Linear(15, 3)\n",
    "    def forward(self, x):\n",
    "        ##print(x)##\n",
    "        #print(\"begin\")\n",
    "        #print(x.shape)\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        #print(\"relu1:\")\n",
    "        #print(x.shape)\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        #print(\"relu2:\")\n",
    "        #print(x.shape)\n",
    "        x = x.view(-1,40)\n",
    "        #print(\"view:\")\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #print(\"relu3:\")\n",
    "        #print(x.shape)\n",
    "        x = F.dropout(x, training=self.training) \n",
    "        #print(\"dropout\")\n",
    "        #print(x.shape)\n",
    "        x = self.fc2(x)\n",
    "        #print(\"fc2\")\n",
    "        #print(x.shape)\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "network = Net()\n",
    "optimizer = optim.Adam(network.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b662f7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Net()\n",
    "optimizer = optim.Adam(network.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918df2cd",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f2ff4f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        #print(data.shape)\n",
    "        #print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "17471c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/1260 (0%)]\tLoss: 1.108506\n",
      "Train Epoch: 0 [60/1260 (5%)]\tLoss: 1.140456\n",
      "Train Epoch: 0 [120/1260 (10%)]\tLoss: 1.083279\n",
      "Train Epoch: 0 [180/1260 (14%)]\tLoss: 1.070431\n",
      "Train Epoch: 0 [240/1260 (19%)]\tLoss: 1.030589\n",
      "Train Epoch: 0 [300/1260 (24%)]\tLoss: 0.987474\n",
      "Train Epoch: 0 [360/1260 (29%)]\tLoss: 1.045798\n",
      "Train Epoch: 0 [420/1260 (33%)]\tLoss: 0.982399\n",
      "Train Epoch: 0 [480/1260 (38%)]\tLoss: 0.989617\n",
      "Train Epoch: 0 [540/1260 (43%)]\tLoss: 1.048126\n",
      "Train Epoch: 0 [600/1260 (48%)]\tLoss: 0.907860\n",
      "Train Epoch: 0 [660/1260 (52%)]\tLoss: 0.755922\n",
      "Train Epoch: 0 [720/1260 (57%)]\tLoss: 0.786310\n",
      "Train Epoch: 0 [780/1260 (62%)]\tLoss: 0.779890\n",
      "Train Epoch: 0 [840/1260 (67%)]\tLoss: 0.694518\n",
      "Train Epoch: 0 [900/1260 (71%)]\tLoss: 0.621619\n",
      "Train Epoch: 0 [960/1260 (76%)]\tLoss: 0.944931\n",
      "Train Epoch: 0 [1020/1260 (81%)]\tLoss: 0.385451\n",
      "Train Epoch: 0 [1080/1260 (86%)]\tLoss: 0.420220\n",
      "Train Epoch: 0 [1140/1260 (90%)]\tLoss: 0.636430\n",
      "Train Epoch: 0 [1200/1260 (95%)]\tLoss: 0.602144\n",
      "Train Epoch: 1 [0/1260 (0%)]\tLoss: 0.426430\n",
      "Train Epoch: 1 [60/1260 (5%)]\tLoss: 0.473426\n",
      "Train Epoch: 1 [120/1260 (10%)]\tLoss: 0.717779\n",
      "Train Epoch: 1 [180/1260 (14%)]\tLoss: 0.267956\n",
      "Train Epoch: 1 [240/1260 (19%)]\tLoss: 0.592568\n",
      "Train Epoch: 1 [300/1260 (24%)]\tLoss: 0.428321\n",
      "Train Epoch: 1 [360/1260 (29%)]\tLoss: 0.278705\n",
      "Train Epoch: 1 [420/1260 (33%)]\tLoss: 0.266086\n",
      "Train Epoch: 1 [480/1260 (38%)]\tLoss: 0.334750\n",
      "Train Epoch: 1 [540/1260 (43%)]\tLoss: 0.322224\n",
      "Train Epoch: 1 [600/1260 (48%)]\tLoss: 0.897352\n",
      "Train Epoch: 1 [660/1260 (52%)]\tLoss: 0.105050\n",
      "Train Epoch: 1 [720/1260 (57%)]\tLoss: 0.271085\n",
      "Train Epoch: 1 [780/1260 (62%)]\tLoss: 0.229835\n",
      "Train Epoch: 1 [840/1260 (67%)]\tLoss: 0.350131\n",
      "Train Epoch: 1 [900/1260 (71%)]\tLoss: 0.136743\n",
      "Train Epoch: 1 [960/1260 (76%)]\tLoss: 0.319654\n",
      "Train Epoch: 1 [1020/1260 (81%)]\tLoss: 0.225946\n",
      "Train Epoch: 1 [1080/1260 (86%)]\tLoss: 0.200179\n",
      "Train Epoch: 1 [1140/1260 (90%)]\tLoss: 0.197193\n",
      "Train Epoch: 1 [1200/1260 (95%)]\tLoss: 0.088717\n",
      "Train Epoch: 2 [0/1260 (0%)]\tLoss: 0.529138\n",
      "Train Epoch: 2 [60/1260 (5%)]\tLoss: 0.200929\n",
      "Train Epoch: 2 [120/1260 (10%)]\tLoss: 0.124355\n",
      "Train Epoch: 2 [180/1260 (14%)]\tLoss: 0.371636\n",
      "Train Epoch: 2 [240/1260 (19%)]\tLoss: 0.099182\n",
      "Train Epoch: 2 [300/1260 (24%)]\tLoss: 0.371965\n",
      "Train Epoch: 2 [360/1260 (29%)]\tLoss: 0.344503\n",
      "Train Epoch: 2 [420/1260 (33%)]\tLoss: 0.077093\n",
      "Train Epoch: 2 [480/1260 (38%)]\tLoss: 0.195582\n",
      "Train Epoch: 2 [540/1260 (43%)]\tLoss: 0.129143\n",
      "Train Epoch: 2 [600/1260 (48%)]\tLoss: 0.358329\n",
      "Train Epoch: 2 [660/1260 (52%)]\tLoss: 0.161078\n",
      "Train Epoch: 2 [720/1260 (57%)]\tLoss: 0.151669\n",
      "Train Epoch: 2 [780/1260 (62%)]\tLoss: 0.190114\n",
      "Train Epoch: 2 [840/1260 (67%)]\tLoss: 0.174554\n",
      "Train Epoch: 2 [900/1260 (71%)]\tLoss: 0.119023\n",
      "Train Epoch: 2 [960/1260 (76%)]\tLoss: 0.038647\n",
      "Train Epoch: 2 [1020/1260 (81%)]\tLoss: 0.279608\n",
      "Train Epoch: 2 [1080/1260 (86%)]\tLoss: 0.132589\n",
      "Train Epoch: 2 [1140/1260 (90%)]\tLoss: 0.095823\n",
      "Train Epoch: 2 [1200/1260 (95%)]\tLoss: 0.939071\n",
      "Train Epoch: 3 [0/1260 (0%)]\tLoss: 0.127909\n",
      "Train Epoch: 3 [60/1260 (5%)]\tLoss: 0.024890\n",
      "Train Epoch: 3 [120/1260 (10%)]\tLoss: 0.786989\n",
      "Train Epoch: 3 [180/1260 (14%)]\tLoss: 0.351985\n",
      "Train Epoch: 3 [240/1260 (19%)]\tLoss: 0.081895\n",
      "Train Epoch: 3 [300/1260 (24%)]\tLoss: 0.037637\n",
      "Train Epoch: 3 [360/1260 (29%)]\tLoss: 0.052643\n",
      "Train Epoch: 3 [420/1260 (33%)]\tLoss: 0.255774\n",
      "Train Epoch: 3 [480/1260 (38%)]\tLoss: 0.260602\n",
      "Train Epoch: 3 [540/1260 (43%)]\tLoss: 0.204367\n",
      "Train Epoch: 3 [600/1260 (48%)]\tLoss: 0.199231\n",
      "Train Epoch: 3 [660/1260 (52%)]\tLoss: 0.255255\n",
      "Train Epoch: 3 [720/1260 (57%)]\tLoss: 0.229295\n",
      "Train Epoch: 3 [780/1260 (62%)]\tLoss: 0.215868\n",
      "Train Epoch: 3 [840/1260 (67%)]\tLoss: 0.052811\n",
      "Train Epoch: 3 [900/1260 (71%)]\tLoss: 0.061115\n",
      "Train Epoch: 3 [960/1260 (76%)]\tLoss: 0.102792\n",
      "Train Epoch: 3 [1020/1260 (81%)]\tLoss: 0.094981\n",
      "Train Epoch: 3 [1080/1260 (86%)]\tLoss: 0.047333\n",
      "Train Epoch: 3 [1140/1260 (90%)]\tLoss: 0.104748\n",
      "Train Epoch: 3 [1200/1260 (95%)]\tLoss: 0.082461\n",
      "Train Epoch: 4 [0/1260 (0%)]\tLoss: 0.013279\n",
      "Train Epoch: 4 [60/1260 (5%)]\tLoss: 0.017278\n",
      "Train Epoch: 4 [120/1260 (10%)]\tLoss: 0.103762\n",
      "Train Epoch: 4 [180/1260 (14%)]\tLoss: 0.301093\n",
      "Train Epoch: 4 [240/1260 (19%)]\tLoss: 0.026639\n",
      "Train Epoch: 4 [300/1260 (24%)]\tLoss: 0.043258\n",
      "Train Epoch: 4 [360/1260 (29%)]\tLoss: 0.112358\n",
      "Train Epoch: 4 [420/1260 (33%)]\tLoss: 0.075176\n",
      "Train Epoch: 4 [480/1260 (38%)]\tLoss: 0.063585\n",
      "Train Epoch: 4 [540/1260 (43%)]\tLoss: 0.018204\n",
      "Train Epoch: 4 [600/1260 (48%)]\tLoss: 0.047546\n",
      "Train Epoch: 4 [660/1260 (52%)]\tLoss: 0.057842\n",
      "Train Epoch: 4 [720/1260 (57%)]\tLoss: 0.314942\n",
      "Train Epoch: 4 [780/1260 (62%)]\tLoss: 0.068498\n",
      "Train Epoch: 4 [840/1260 (67%)]\tLoss: 0.087123\n",
      "Train Epoch: 4 [900/1260 (71%)]\tLoss: 0.078900\n",
      "Train Epoch: 4 [960/1260 (76%)]\tLoss: 0.394152\n",
      "Train Epoch: 4 [1020/1260 (81%)]\tLoss: 0.020366\n",
      "Train Epoch: 4 [1080/1260 (86%)]\tLoss: 0.140341\n",
      "Train Epoch: 4 [1140/1260 (90%)]\tLoss: 0.085646\n",
      "Train Epoch: 4 [1200/1260 (95%)]\tLoss: 0.394651\n",
      "Train Epoch: 5 [0/1260 (0%)]\tLoss: 0.143898\n",
      "Train Epoch: 5 [60/1260 (5%)]\tLoss: 0.074619\n",
      "Train Epoch: 5 [120/1260 (10%)]\tLoss: 0.012171\n",
      "Train Epoch: 5 [180/1260 (14%)]\tLoss: 0.102353\n",
      "Train Epoch: 5 [240/1260 (19%)]\tLoss: 0.003858\n",
      "Train Epoch: 5 [300/1260 (24%)]\tLoss: 0.020226\n",
      "Train Epoch: 5 [360/1260 (29%)]\tLoss: 0.014811\n",
      "Train Epoch: 5 [420/1260 (33%)]\tLoss: 0.165567\n",
      "Train Epoch: 5 [480/1260 (38%)]\tLoss: 0.007362\n",
      "Train Epoch: 5 [540/1260 (43%)]\tLoss: 0.044706\n",
      "Train Epoch: 5 [600/1260 (48%)]\tLoss: 0.014209\n",
      "Train Epoch: 5 [660/1260 (52%)]\tLoss: 0.042465\n",
      "Train Epoch: 5 [720/1260 (57%)]\tLoss: 0.015554\n",
      "Train Epoch: 5 [780/1260 (62%)]\tLoss: 0.332034\n",
      "Train Epoch: 5 [840/1260 (67%)]\tLoss: 0.007899\n",
      "Train Epoch: 5 [900/1260 (71%)]\tLoss: 0.167931\n",
      "Train Epoch: 5 [960/1260 (76%)]\tLoss: 0.001311\n",
      "Train Epoch: 5 [1020/1260 (81%)]\tLoss: 0.005862\n",
      "Train Epoch: 5 [1080/1260 (86%)]\tLoss: 0.102393\n",
      "Train Epoch: 5 [1140/1260 (90%)]\tLoss: 0.007544\n",
      "Train Epoch: 5 [1200/1260 (95%)]\tLoss: 0.003098\n",
      "Train Epoch: 6 [0/1260 (0%)]\tLoss: 0.209764\n",
      "Train Epoch: 6 [60/1260 (5%)]\tLoss: 0.352059\n",
      "Train Epoch: 6 [120/1260 (10%)]\tLoss: 0.021165\n",
      "Train Epoch: 6 [180/1260 (14%)]\tLoss: 0.080461\n",
      "Train Epoch: 6 [240/1260 (19%)]\tLoss: 0.024274\n",
      "Train Epoch: 6 [300/1260 (24%)]\tLoss: 0.014459\n",
      "Train Epoch: 6 [360/1260 (29%)]\tLoss: 0.022397\n",
      "Train Epoch: 6 [420/1260 (33%)]\tLoss: 0.065377\n",
      "Train Epoch: 6 [480/1260 (38%)]\tLoss: 0.203878\n",
      "Train Epoch: 6 [540/1260 (43%)]\tLoss: 0.631190\n",
      "Train Epoch: 6 [600/1260 (48%)]\tLoss: 0.003468\n",
      "Train Epoch: 6 [660/1260 (52%)]\tLoss: 0.133855\n",
      "Train Epoch: 6 [720/1260 (57%)]\tLoss: 0.003717\n",
      "Train Epoch: 6 [780/1260 (62%)]\tLoss: 1.125764\n",
      "Train Epoch: 6 [840/1260 (67%)]\tLoss: 0.316312\n",
      "Train Epoch: 6 [900/1260 (71%)]\tLoss: 0.159323\n",
      "Train Epoch: 6 [960/1260 (76%)]\tLoss: 0.004020\n",
      "Train Epoch: 6 [1020/1260 (81%)]\tLoss: 0.097344\n",
      "Train Epoch: 6 [1080/1260 (86%)]\tLoss: 0.090101\n",
      "Train Epoch: 6 [1140/1260 (90%)]\tLoss: 0.095017\n",
      "Train Epoch: 6 [1200/1260 (95%)]\tLoss: 0.020123\n",
      "Train Epoch: 7 [0/1260 (0%)]\tLoss: 0.050985\n",
      "Train Epoch: 7 [60/1260 (5%)]\tLoss: 0.031867\n",
      "Train Epoch: 7 [120/1260 (10%)]\tLoss: 0.186880\n",
      "Train Epoch: 7 [180/1260 (14%)]\tLoss: 0.012594\n",
      "Train Epoch: 7 [240/1260 (19%)]\tLoss: 0.808600\n",
      "Train Epoch: 7 [300/1260 (24%)]\tLoss: 0.040453\n",
      "Train Epoch: 7 [360/1260 (29%)]\tLoss: 0.010140\n",
      "Train Epoch: 7 [420/1260 (33%)]\tLoss: 0.082236\n",
      "Train Epoch: 7 [480/1260 (38%)]\tLoss: 0.079899\n",
      "Train Epoch: 7 [540/1260 (43%)]\tLoss: 0.026668\n",
      "Train Epoch: 7 [600/1260 (48%)]\tLoss: 0.119065\n",
      "Train Epoch: 7 [660/1260 (52%)]\tLoss: 0.093196\n",
      "Train Epoch: 7 [720/1260 (57%)]\tLoss: 0.005892\n",
      "Train Epoch: 7 [780/1260 (62%)]\tLoss: 0.063811\n",
      "Train Epoch: 7 [840/1260 (67%)]\tLoss: 0.050968\n",
      "Train Epoch: 7 [900/1260 (71%)]\tLoss: 0.036538\n",
      "Train Epoch: 7 [960/1260 (76%)]\tLoss: 0.007845\n",
      "Train Epoch: 7 [1020/1260 (81%)]\tLoss: 0.002829\n",
      "Train Epoch: 7 [1080/1260 (86%)]\tLoss: 0.003186\n",
      "Train Epoch: 7 [1140/1260 (90%)]\tLoss: 0.006260\n",
      "Train Epoch: 7 [1200/1260 (95%)]\tLoss: 0.017694\n",
      "Train Epoch: 8 [0/1260 (0%)]\tLoss: 0.134574\n",
      "Train Epoch: 8 [60/1260 (5%)]\tLoss: 0.109527\n",
      "Train Epoch: 8 [120/1260 (10%)]\tLoss: 0.008231\n",
      "Train Epoch: 8 [180/1260 (14%)]\tLoss: 0.014804\n",
      "Train Epoch: 8 [240/1260 (19%)]\tLoss: 0.023172\n",
      "Train Epoch: 8 [300/1260 (24%)]\tLoss: 0.348791\n",
      "Train Epoch: 8 [360/1260 (29%)]\tLoss: 0.056814\n",
      "Train Epoch: 8 [420/1260 (33%)]\tLoss: 0.126877\n",
      "Train Epoch: 8 [480/1260 (38%)]\tLoss: 0.019649\n",
      "Train Epoch: 8 [540/1260 (43%)]\tLoss: 0.113361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [600/1260 (48%)]\tLoss: 0.002773\n",
      "Train Epoch: 8 [660/1260 (52%)]\tLoss: 0.226434\n",
      "Train Epoch: 8 [720/1260 (57%)]\tLoss: 0.002663\n",
      "Train Epoch: 8 [780/1260 (62%)]\tLoss: 0.008624\n",
      "Train Epoch: 8 [840/1260 (67%)]\tLoss: 0.084532\n",
      "Train Epoch: 8 [900/1260 (71%)]\tLoss: 0.028450\n",
      "Train Epoch: 8 [960/1260 (76%)]\tLoss: 0.077726\n",
      "Train Epoch: 8 [1020/1260 (81%)]\tLoss: 0.695272\n",
      "Train Epoch: 8 [1080/1260 (86%)]\tLoss: 0.017768\n",
      "Train Epoch: 8 [1140/1260 (90%)]\tLoss: 0.002724\n",
      "Train Epoch: 8 [1200/1260 (95%)]\tLoss: 0.015567\n",
      "Train Epoch: 9 [0/1260 (0%)]\tLoss: 0.168633\n",
      "Train Epoch: 9 [60/1260 (5%)]\tLoss: 0.001261\n",
      "Train Epoch: 9 [120/1260 (10%)]\tLoss: 0.014396\n",
      "Train Epoch: 9 [180/1260 (14%)]\tLoss: 0.015210\n",
      "Train Epoch: 9 [240/1260 (19%)]\tLoss: 0.215256\n",
      "Train Epoch: 9 [300/1260 (24%)]\tLoss: 0.005290\n",
      "Train Epoch: 9 [360/1260 (29%)]\tLoss: 0.010459\n",
      "Train Epoch: 9 [420/1260 (33%)]\tLoss: 0.030540\n",
      "Train Epoch: 9 [480/1260 (38%)]\tLoss: 0.002684\n",
      "Train Epoch: 9 [540/1260 (43%)]\tLoss: 0.002572\n",
      "Train Epoch: 9 [600/1260 (48%)]\tLoss: 0.016146\n",
      "Train Epoch: 9 [660/1260 (52%)]\tLoss: 0.194607\n",
      "Train Epoch: 9 [720/1260 (57%)]\tLoss: 0.022747\n",
      "Train Epoch: 9 [780/1260 (62%)]\tLoss: 0.017038\n",
      "Train Epoch: 9 [840/1260 (67%)]\tLoss: 0.000888\n",
      "Train Epoch: 9 [900/1260 (71%)]\tLoss: 0.030701\n",
      "Train Epoch: 9 [960/1260 (76%)]\tLoss: 0.011668\n",
      "Train Epoch: 9 [1020/1260 (81%)]\tLoss: 0.133568\n",
      "Train Epoch: 9 [1080/1260 (86%)]\tLoss: 0.046217\n",
      "Train Epoch: 9 [1140/1260 (90%)]\tLoss: 0.071247\n",
      "Train Epoch: 9 [1200/1260 (95%)]\tLoss: 1.534894\n",
      "Train Epoch: 10 [0/1260 (0%)]\tLoss: 0.021804\n",
      "Train Epoch: 10 [60/1260 (5%)]\tLoss: 0.014688\n",
      "Train Epoch: 10 [120/1260 (10%)]\tLoss: 0.004965\n",
      "Train Epoch: 10 [180/1260 (14%)]\tLoss: 0.024440\n",
      "Train Epoch: 10 [240/1260 (19%)]\tLoss: 0.036854\n",
      "Train Epoch: 10 [300/1260 (24%)]\tLoss: 0.250125\n",
      "Train Epoch: 10 [360/1260 (29%)]\tLoss: 0.011141\n",
      "Train Epoch: 10 [420/1260 (33%)]\tLoss: 0.194112\n",
      "Train Epoch: 10 [480/1260 (38%)]\tLoss: 0.019545\n",
      "Train Epoch: 10 [540/1260 (43%)]\tLoss: 0.127262\n",
      "Train Epoch: 10 [600/1260 (48%)]\tLoss: 0.240177\n",
      "Train Epoch: 10 [660/1260 (52%)]\tLoss: 0.018931\n",
      "Train Epoch: 10 [720/1260 (57%)]\tLoss: 0.016925\n",
      "Train Epoch: 10 [780/1260 (62%)]\tLoss: 0.007624\n",
      "Train Epoch: 10 [840/1260 (67%)]\tLoss: 0.166205\n",
      "Train Epoch: 10 [900/1260 (71%)]\tLoss: 0.014130\n",
      "Train Epoch: 10 [960/1260 (76%)]\tLoss: 0.000229\n",
      "Train Epoch: 10 [1020/1260 (81%)]\tLoss: 0.039031\n",
      "Train Epoch: 10 [1080/1260 (86%)]\tLoss: 0.026756\n",
      "Train Epoch: 10 [1140/1260 (90%)]\tLoss: 0.027248\n",
      "Train Epoch: 10 [1200/1260 (95%)]\tLoss: 0.248419\n",
      "Train Epoch: 11 [0/1260 (0%)]\tLoss: 0.000158\n",
      "Train Epoch: 11 [60/1260 (5%)]\tLoss: 0.002417\n",
      "Train Epoch: 11 [120/1260 (10%)]\tLoss: 0.128090\n",
      "Train Epoch: 11 [180/1260 (14%)]\tLoss: 0.034874\n",
      "Train Epoch: 11 [240/1260 (19%)]\tLoss: 0.002318\n",
      "Train Epoch: 11 [300/1260 (24%)]\tLoss: 0.000270\n",
      "Train Epoch: 11 [360/1260 (29%)]\tLoss: 0.015501\n",
      "Train Epoch: 11 [420/1260 (33%)]\tLoss: 0.038467\n",
      "Train Epoch: 11 [480/1260 (38%)]\tLoss: 0.014452\n",
      "Train Epoch: 11 [540/1260 (43%)]\tLoss: 0.006808\n",
      "Train Epoch: 11 [600/1260 (48%)]\tLoss: 0.027222\n",
      "Train Epoch: 11 [660/1260 (52%)]\tLoss: 0.015129\n",
      "Train Epoch: 11 [720/1260 (57%)]\tLoss: 0.007788\n",
      "Train Epoch: 11 [780/1260 (62%)]\tLoss: 0.189052\n",
      "Train Epoch: 11 [840/1260 (67%)]\tLoss: 0.007317\n",
      "Train Epoch: 11 [900/1260 (71%)]\tLoss: 0.034462\n",
      "Train Epoch: 11 [960/1260 (76%)]\tLoss: 0.000344\n",
      "Train Epoch: 11 [1020/1260 (81%)]\tLoss: 0.053326\n",
      "Train Epoch: 11 [1080/1260 (86%)]\tLoss: 0.191941\n",
      "Train Epoch: 11 [1140/1260 (90%)]\tLoss: 0.020407\n",
      "Train Epoch: 11 [1200/1260 (95%)]\tLoss: 0.476854\n",
      "Train Epoch: 12 [0/1260 (0%)]\tLoss: 0.023871\n",
      "Train Epoch: 12 [60/1260 (5%)]\tLoss: 0.005980\n",
      "Train Epoch: 12 [120/1260 (10%)]\tLoss: 0.016221\n",
      "Train Epoch: 12 [180/1260 (14%)]\tLoss: 0.201682\n",
      "Train Epoch: 12 [240/1260 (19%)]\tLoss: 0.037369\n",
      "Train Epoch: 12 [300/1260 (24%)]\tLoss: 0.009999\n",
      "Train Epoch: 12 [360/1260 (29%)]\tLoss: 0.017281\n",
      "Train Epoch: 12 [420/1260 (33%)]\tLoss: 0.042660\n",
      "Train Epoch: 12 [480/1260 (38%)]\tLoss: 0.159961\n",
      "Train Epoch: 12 [540/1260 (43%)]\tLoss: 0.004829\n",
      "Train Epoch: 12 [600/1260 (48%)]\tLoss: 0.051234\n",
      "Train Epoch: 12 [660/1260 (52%)]\tLoss: 0.030044\n",
      "Train Epoch: 12 [720/1260 (57%)]\tLoss: 0.008447\n",
      "Train Epoch: 12 [780/1260 (62%)]\tLoss: 0.001264\n",
      "Train Epoch: 12 [840/1260 (67%)]\tLoss: 0.279519\n",
      "Train Epoch: 12 [900/1260 (71%)]\tLoss: 0.003159\n",
      "Train Epoch: 12 [960/1260 (76%)]\tLoss: 0.442047\n",
      "Train Epoch: 12 [1020/1260 (81%)]\tLoss: 0.018869\n",
      "Train Epoch: 12 [1080/1260 (86%)]\tLoss: 0.330604\n",
      "Train Epoch: 12 [1140/1260 (90%)]\tLoss: 0.052910\n",
      "Train Epoch: 12 [1200/1260 (95%)]\tLoss: 0.014063\n",
      "Train Epoch: 13 [0/1260 (0%)]\tLoss: 0.065180\n",
      "Train Epoch: 13 [60/1260 (5%)]\tLoss: 0.020197\n",
      "Train Epoch: 13 [120/1260 (10%)]\tLoss: 0.048043\n",
      "Train Epoch: 13 [180/1260 (14%)]\tLoss: 0.003820\n",
      "Train Epoch: 13 [240/1260 (19%)]\tLoss: 0.013624\n",
      "Train Epoch: 13 [300/1260 (24%)]\tLoss: 0.035301\n",
      "Train Epoch: 13 [360/1260 (29%)]\tLoss: 0.008559\n",
      "Train Epoch: 13 [420/1260 (33%)]\tLoss: 0.007450\n",
      "Train Epoch: 13 [480/1260 (38%)]\tLoss: 0.072297\n",
      "Train Epoch: 13 [540/1260 (43%)]\tLoss: 0.001416\n",
      "Train Epoch: 13 [600/1260 (48%)]\tLoss: 0.005814\n",
      "Train Epoch: 13 [660/1260 (52%)]\tLoss: 0.016685\n",
      "Train Epoch: 13 [720/1260 (57%)]\tLoss: 0.036631\n",
      "Train Epoch: 13 [780/1260 (62%)]\tLoss: 0.003723\n",
      "Train Epoch: 13 [840/1260 (67%)]\tLoss: 0.034271\n",
      "Train Epoch: 13 [900/1260 (71%)]\tLoss: 0.059665\n",
      "Train Epoch: 13 [960/1260 (76%)]\tLoss: 0.033840\n",
      "Train Epoch: 13 [1020/1260 (81%)]\tLoss: 0.000655\n",
      "Train Epoch: 13 [1080/1260 (86%)]\tLoss: 0.004476\n",
      "Train Epoch: 13 [1140/1260 (90%)]\tLoss: 0.004464\n",
      "Train Epoch: 13 [1200/1260 (95%)]\tLoss: 0.052679\n",
      "Train Epoch: 14 [0/1260 (0%)]\tLoss: 0.162937\n",
      "Train Epoch: 14 [60/1260 (5%)]\tLoss: 0.009520\n",
      "Train Epoch: 14 [120/1260 (10%)]\tLoss: 0.036739\n",
      "Train Epoch: 14 [180/1260 (14%)]\tLoss: 0.019707\n",
      "Train Epoch: 14 [240/1260 (19%)]\tLoss: 0.002964\n",
      "Train Epoch: 14 [300/1260 (24%)]\tLoss: 0.004198\n",
      "Train Epoch: 14 [360/1260 (29%)]\tLoss: 0.000567\n",
      "Train Epoch: 14 [420/1260 (33%)]\tLoss: 0.173700\n",
      "Train Epoch: 14 [480/1260 (38%)]\tLoss: 0.199817\n",
      "Train Epoch: 14 [540/1260 (43%)]\tLoss: 0.017243\n",
      "Train Epoch: 14 [600/1260 (48%)]\tLoss: 0.054715\n",
      "Train Epoch: 14 [660/1260 (52%)]\tLoss: 0.037700\n",
      "Train Epoch: 14 [720/1260 (57%)]\tLoss: 0.003328\n",
      "Train Epoch: 14 [780/1260 (62%)]\tLoss: 0.447333\n",
      "Train Epoch: 14 [840/1260 (67%)]\tLoss: 0.000539\n",
      "Train Epoch: 14 [900/1260 (71%)]\tLoss: 0.000498\n",
      "Train Epoch: 14 [960/1260 (76%)]\tLoss: 0.194515\n",
      "Train Epoch: 14 [1020/1260 (81%)]\tLoss: 0.023632\n",
      "Train Epoch: 14 [1080/1260 (86%)]\tLoss: 0.185954\n",
      "Train Epoch: 14 [1140/1260 (90%)]\tLoss: 0.004334\n",
      "Train Epoch: 14 [1200/1260 (95%)]\tLoss: 0.040060\n",
      "Train Epoch: 15 [0/1260 (0%)]\tLoss: 0.006947\n",
      "Train Epoch: 15 [60/1260 (5%)]\tLoss: 0.000759\n",
      "Train Epoch: 15 [120/1260 (10%)]\tLoss: 0.000746\n",
      "Train Epoch: 15 [180/1260 (14%)]\tLoss: 0.018697\n",
      "Train Epoch: 15 [240/1260 (19%)]\tLoss: 0.011891\n",
      "Train Epoch: 15 [300/1260 (24%)]\tLoss: 0.004731\n",
      "Train Epoch: 15 [360/1260 (29%)]\tLoss: 0.717506\n",
      "Train Epoch: 15 [420/1260 (33%)]\tLoss: 0.035253\n",
      "Train Epoch: 15 [480/1260 (38%)]\tLoss: 0.014743\n",
      "Train Epoch: 15 [540/1260 (43%)]\tLoss: 0.000266\n",
      "Train Epoch: 15 [600/1260 (48%)]\tLoss: 0.010623\n",
      "Train Epoch: 15 [660/1260 (52%)]\tLoss: 0.033665\n",
      "Train Epoch: 15 [720/1260 (57%)]\tLoss: 0.030590\n",
      "Train Epoch: 15 [780/1260 (62%)]\tLoss: 0.007153\n",
      "Train Epoch: 15 [840/1260 (67%)]\tLoss: 0.013080\n",
      "Train Epoch: 15 [900/1260 (71%)]\tLoss: 0.061635\n",
      "Train Epoch: 15 [960/1260 (76%)]\tLoss: 0.014153\n",
      "Train Epoch: 15 [1020/1260 (81%)]\tLoss: 0.077826\n",
      "Train Epoch: 15 [1080/1260 (86%)]\tLoss: 0.007319\n",
      "Train Epoch: 15 [1140/1260 (90%)]\tLoss: 0.003048\n",
      "Train Epoch: 15 [1200/1260 (95%)]\tLoss: 0.012163\n",
      "Train Epoch: 16 [0/1260 (0%)]\tLoss: 0.001740\n",
      "Train Epoch: 16 [60/1260 (5%)]\tLoss: 0.038235\n",
      "Train Epoch: 16 [120/1260 (10%)]\tLoss: 0.037384\n",
      "Train Epoch: 16 [180/1260 (14%)]\tLoss: 0.021984\n",
      "Train Epoch: 16 [240/1260 (19%)]\tLoss: 0.033868\n",
      "Train Epoch: 16 [300/1260 (24%)]\tLoss: 0.003603\n",
      "Train Epoch: 16 [360/1260 (29%)]\tLoss: 0.003620\n",
      "Train Epoch: 16 [420/1260 (33%)]\tLoss: 0.060300\n",
      "Train Epoch: 16 [480/1260 (38%)]\tLoss: 0.009346\n",
      "Train Epoch: 16 [540/1260 (43%)]\tLoss: 0.056611\n",
      "Train Epoch: 16 [600/1260 (48%)]\tLoss: 0.007144\n",
      "Train Epoch: 16 [660/1260 (52%)]\tLoss: 0.002091\n",
      "Train Epoch: 16 [720/1260 (57%)]\tLoss: 0.022483\n",
      "Train Epoch: 16 [780/1260 (62%)]\tLoss: 0.001995\n",
      "Train Epoch: 16 [840/1260 (67%)]\tLoss: 0.201419\n",
      "Train Epoch: 16 [900/1260 (71%)]\tLoss: 0.038840\n",
      "Train Epoch: 16 [960/1260 (76%)]\tLoss: 0.859930\n",
      "Train Epoch: 16 [1020/1260 (81%)]\tLoss: 0.023401\n",
      "Train Epoch: 16 [1080/1260 (86%)]\tLoss: 0.314360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 16 [1140/1260 (90%)]\tLoss: 0.001123\n",
      "Train Epoch: 16 [1200/1260 (95%)]\tLoss: 0.008282\n",
      "Train Epoch: 17 [0/1260 (0%)]\tLoss: 0.005810\n",
      "Train Epoch: 17 [60/1260 (5%)]\tLoss: 0.015555\n",
      "Train Epoch: 17 [120/1260 (10%)]\tLoss: 0.022303\n",
      "Train Epoch: 17 [180/1260 (14%)]\tLoss: 0.099529\n",
      "Train Epoch: 17 [240/1260 (19%)]\tLoss: 0.002189\n",
      "Train Epoch: 17 [300/1260 (24%)]\tLoss: 0.002684\n",
      "Train Epoch: 17 [360/1260 (29%)]\tLoss: 0.018320\n",
      "Train Epoch: 17 [420/1260 (33%)]\tLoss: 0.017542\n",
      "Train Epoch: 17 [480/1260 (38%)]\tLoss: 0.007829\n",
      "Train Epoch: 17 [540/1260 (43%)]\tLoss: 0.164458\n",
      "Train Epoch: 17 [600/1260 (48%)]\tLoss: 0.009069\n",
      "Train Epoch: 17 [660/1260 (52%)]\tLoss: 0.083256\n",
      "Train Epoch: 17 [720/1260 (57%)]\tLoss: 0.000657\n",
      "Train Epoch: 17 [780/1260 (62%)]\tLoss: 0.000452\n",
      "Train Epoch: 17 [840/1260 (67%)]\tLoss: 0.000588\n",
      "Train Epoch: 17 [900/1260 (71%)]\tLoss: 0.001066\n",
      "Train Epoch: 17 [960/1260 (76%)]\tLoss: 0.019292\n",
      "Train Epoch: 17 [1020/1260 (81%)]\tLoss: 0.016072\n",
      "Train Epoch: 17 [1080/1260 (86%)]\tLoss: 0.009531\n",
      "Train Epoch: 17 [1140/1260 (90%)]\tLoss: 0.001747\n",
      "Train Epoch: 17 [1200/1260 (95%)]\tLoss: 0.010593\n",
      "Train Epoch: 18 [0/1260 (0%)]\tLoss: 0.000082\n",
      "Train Epoch: 18 [60/1260 (5%)]\tLoss: 0.003731\n",
      "Train Epoch: 18 [120/1260 (10%)]\tLoss: 0.011532\n",
      "Train Epoch: 18 [180/1260 (14%)]\tLoss: 0.289366\n",
      "Train Epoch: 18 [240/1260 (19%)]\tLoss: 0.050338\n",
      "Train Epoch: 18 [300/1260 (24%)]\tLoss: 0.015300\n",
      "Train Epoch: 18 [360/1260 (29%)]\tLoss: 0.008559\n",
      "Train Epoch: 18 [420/1260 (33%)]\tLoss: 0.014187\n",
      "Train Epoch: 18 [480/1260 (38%)]\tLoss: 0.001440\n",
      "Train Epoch: 18 [540/1260 (43%)]\tLoss: 0.131094\n",
      "Train Epoch: 18 [600/1260 (48%)]\tLoss: 0.146831\n",
      "Train Epoch: 18 [660/1260 (52%)]\tLoss: 0.002513\n",
      "Train Epoch: 18 [720/1260 (57%)]\tLoss: 0.044805\n",
      "Train Epoch: 18 [780/1260 (62%)]\tLoss: 0.011197\n",
      "Train Epoch: 18 [840/1260 (67%)]\tLoss: 0.022805\n",
      "Train Epoch: 18 [900/1260 (71%)]\tLoss: 0.113327\n",
      "Train Epoch: 18 [960/1260 (76%)]\tLoss: 0.049297\n",
      "Train Epoch: 18 [1020/1260 (81%)]\tLoss: 0.000932\n",
      "Train Epoch: 18 [1080/1260 (86%)]\tLoss: 0.831993\n",
      "Train Epoch: 18 [1140/1260 (90%)]\tLoss: 0.886444\n",
      "Train Epoch: 18 [1200/1260 (95%)]\tLoss: 0.030744\n",
      "Train Epoch: 19 [0/1260 (0%)]\tLoss: 0.130447\n",
      "Train Epoch: 19 [60/1260 (5%)]\tLoss: 0.048431\n",
      "Train Epoch: 19 [120/1260 (10%)]\tLoss: 0.175154\n",
      "Train Epoch: 19 [180/1260 (14%)]\tLoss: 0.130537\n",
      "Train Epoch: 19 [240/1260 (19%)]\tLoss: 0.361054\n",
      "Train Epoch: 19 [300/1260 (24%)]\tLoss: 0.045232\n",
      "Train Epoch: 19 [360/1260 (29%)]\tLoss: 0.029852\n",
      "Train Epoch: 19 [420/1260 (33%)]\tLoss: 0.205753\n",
      "Train Epoch: 19 [480/1260 (38%)]\tLoss: 0.002214\n",
      "Train Epoch: 19 [540/1260 (43%)]\tLoss: 0.001943\n",
      "Train Epoch: 19 [600/1260 (48%)]\tLoss: 0.006981\n",
      "Train Epoch: 19 [660/1260 (52%)]\tLoss: 0.003579\n",
      "Train Epoch: 19 [720/1260 (57%)]\tLoss: 0.003388\n",
      "Train Epoch: 19 [780/1260 (62%)]\tLoss: 0.047194\n",
      "Train Epoch: 19 [840/1260 (67%)]\tLoss: 0.035228\n",
      "Train Epoch: 19 [900/1260 (71%)]\tLoss: 0.030001\n",
      "Train Epoch: 19 [960/1260 (76%)]\tLoss: 0.002876\n",
      "Train Epoch: 19 [1020/1260 (81%)]\tLoss: 0.025322\n",
      "Train Epoch: 19 [1080/1260 (86%)]\tLoss: 0.027375\n",
      "Train Epoch: 19 [1140/1260 (90%)]\tLoss: 0.007487\n",
      "Train Epoch: 19 [1200/1260 (95%)]\tLoss: 0.001378\n",
      "Train Epoch: 20 [0/1260 (0%)]\tLoss: 0.077721\n",
      "Train Epoch: 20 [60/1260 (5%)]\tLoss: 0.131613\n",
      "Train Epoch: 20 [120/1260 (10%)]\tLoss: 0.010552\n",
      "Train Epoch: 20 [180/1260 (14%)]\tLoss: 0.024051\n",
      "Train Epoch: 20 [240/1260 (19%)]\tLoss: 0.002293\n",
      "Train Epoch: 20 [300/1260 (24%)]\tLoss: 0.000193\n",
      "Train Epoch: 20 [360/1260 (29%)]\tLoss: 0.000540\n",
      "Train Epoch: 20 [420/1260 (33%)]\tLoss: 0.044636\n",
      "Train Epoch: 20 [480/1260 (38%)]\tLoss: 0.024395\n",
      "Train Epoch: 20 [540/1260 (43%)]\tLoss: 0.005454\n",
      "Train Epoch: 20 [600/1260 (48%)]\tLoss: 0.523362\n",
      "Train Epoch: 20 [660/1260 (52%)]\tLoss: 0.031512\n",
      "Train Epoch: 20 [720/1260 (57%)]\tLoss: 0.002461\n",
      "Train Epoch: 20 [780/1260 (62%)]\tLoss: 0.015040\n",
      "Train Epoch: 20 [840/1260 (67%)]\tLoss: 0.002960\n",
      "Train Epoch: 20 [900/1260 (71%)]\tLoss: 0.010385\n",
      "Train Epoch: 20 [960/1260 (76%)]\tLoss: 0.050873\n",
      "Train Epoch: 20 [1020/1260 (81%)]\tLoss: 0.000712\n",
      "Train Epoch: 20 [1080/1260 (86%)]\tLoss: 0.018727\n",
      "Train Epoch: 20 [1140/1260 (90%)]\tLoss: 0.001860\n",
      "Train Epoch: 20 [1200/1260 (95%)]\tLoss: 0.036109\n",
      "Train Epoch: 21 [0/1260 (0%)]\tLoss: 0.002795\n",
      "Train Epoch: 21 [60/1260 (5%)]\tLoss: 0.000473\n",
      "Train Epoch: 21 [120/1260 (10%)]\tLoss: 0.021614\n",
      "Train Epoch: 21 [180/1260 (14%)]\tLoss: 0.014222\n",
      "Train Epoch: 21 [240/1260 (19%)]\tLoss: 0.840734\n",
      "Train Epoch: 21 [300/1260 (24%)]\tLoss: 0.036232\n",
      "Train Epoch: 21 [360/1260 (29%)]\tLoss: 0.126844\n",
      "Train Epoch: 21 [420/1260 (33%)]\tLoss: 0.023741\n",
      "Train Epoch: 21 [480/1260 (38%)]\tLoss: 0.023925\n",
      "Train Epoch: 21 [540/1260 (43%)]\tLoss: 0.006573\n",
      "Train Epoch: 21 [600/1260 (48%)]\tLoss: 0.047729\n",
      "Train Epoch: 21 [660/1260 (52%)]\tLoss: 0.005826\n",
      "Train Epoch: 21 [720/1260 (57%)]\tLoss: 0.009561\n",
      "Train Epoch: 21 [780/1260 (62%)]\tLoss: 0.004000\n",
      "Train Epoch: 21 [840/1260 (67%)]\tLoss: 0.023464\n",
      "Train Epoch: 21 [900/1260 (71%)]\tLoss: 0.026217\n",
      "Train Epoch: 21 [960/1260 (76%)]\tLoss: 0.048911\n",
      "Train Epoch: 21 [1020/1260 (81%)]\tLoss: 0.006697\n",
      "Train Epoch: 21 [1080/1260 (86%)]\tLoss: 0.174475\n",
      "Train Epoch: 21 [1140/1260 (90%)]\tLoss: 0.002090\n",
      "Train Epoch: 21 [1200/1260 (95%)]\tLoss: 0.002746\n",
      "Train Epoch: 22 [0/1260 (0%)]\tLoss: 0.853767\n",
      "Train Epoch: 22 [60/1260 (5%)]\tLoss: 0.039070\n",
      "Train Epoch: 22 [120/1260 (10%)]\tLoss: 0.005772\n",
      "Train Epoch: 22 [180/1260 (14%)]\tLoss: 0.112042\n",
      "Train Epoch: 22 [240/1260 (19%)]\tLoss: 0.000792\n",
      "Train Epoch: 22 [300/1260 (24%)]\tLoss: 0.014726\n",
      "Train Epoch: 22 [360/1260 (29%)]\tLoss: 0.000440\n",
      "Train Epoch: 22 [420/1260 (33%)]\tLoss: 0.019907\n",
      "Train Epoch: 22 [480/1260 (38%)]\tLoss: 0.013764\n",
      "Train Epoch: 22 [540/1260 (43%)]\tLoss: 0.225392\n",
      "Train Epoch: 22 [600/1260 (48%)]\tLoss: 0.180291\n",
      "Train Epoch: 22 [660/1260 (52%)]\tLoss: 0.016073\n",
      "Train Epoch: 22 [720/1260 (57%)]\tLoss: 0.036906\n",
      "Train Epoch: 22 [780/1260 (62%)]\tLoss: 0.015935\n",
      "Train Epoch: 22 [840/1260 (67%)]\tLoss: 0.041205\n",
      "Train Epoch: 22 [900/1260 (71%)]\tLoss: 0.043701\n",
      "Train Epoch: 22 [960/1260 (76%)]\tLoss: 0.028699\n",
      "Train Epoch: 22 [1020/1260 (81%)]\tLoss: 0.001608\n",
      "Train Epoch: 22 [1080/1260 (86%)]\tLoss: 0.001377\n",
      "Train Epoch: 22 [1140/1260 (90%)]\tLoss: 0.235103\n",
      "Train Epoch: 22 [1200/1260 (95%)]\tLoss: 0.003832\n",
      "Train Epoch: 23 [0/1260 (0%)]\tLoss: 0.012773\n",
      "Train Epoch: 23 [60/1260 (5%)]\tLoss: 0.056966\n",
      "Train Epoch: 23 [120/1260 (10%)]\tLoss: 0.000758\n",
      "Train Epoch: 23 [180/1260 (14%)]\tLoss: 0.009093\n",
      "Train Epoch: 23 [240/1260 (19%)]\tLoss: 0.014865\n",
      "Train Epoch: 23 [300/1260 (24%)]\tLoss: 0.788410\n",
      "Train Epoch: 23 [360/1260 (29%)]\tLoss: 0.006599\n",
      "Train Epoch: 23 [420/1260 (33%)]\tLoss: 0.015959\n",
      "Train Epoch: 23 [480/1260 (38%)]\tLoss: 0.000578\n",
      "Train Epoch: 23 [540/1260 (43%)]\tLoss: 0.000554\n",
      "Train Epoch: 23 [600/1260 (48%)]\tLoss: 0.170762\n",
      "Train Epoch: 23 [660/1260 (52%)]\tLoss: 0.011030\n",
      "Train Epoch: 23 [720/1260 (57%)]\tLoss: 0.000126\n",
      "Train Epoch: 23 [780/1260 (62%)]\tLoss: 0.000003\n",
      "Train Epoch: 23 [840/1260 (67%)]\tLoss: 0.153438\n",
      "Train Epoch: 23 [900/1260 (71%)]\tLoss: 0.351273\n",
      "Train Epoch: 23 [960/1260 (76%)]\tLoss: 0.389565\n",
      "Train Epoch: 23 [1020/1260 (81%)]\tLoss: 0.002030\n",
      "Train Epoch: 23 [1080/1260 (86%)]\tLoss: 0.007479\n",
      "Train Epoch: 23 [1140/1260 (90%)]\tLoss: 0.035132\n",
      "Train Epoch: 23 [1200/1260 (95%)]\tLoss: 0.000164\n",
      "Train Epoch: 24 [0/1260 (0%)]\tLoss: 0.002178\n",
      "Train Epoch: 24 [60/1260 (5%)]\tLoss: 0.043469\n",
      "Train Epoch: 24 [120/1260 (10%)]\tLoss: 0.159413\n",
      "Train Epoch: 24 [180/1260 (14%)]\tLoss: 0.023350\n",
      "Train Epoch: 24 [240/1260 (19%)]\tLoss: 0.194784\n",
      "Train Epoch: 24 [300/1260 (24%)]\tLoss: 0.001286\n",
      "Train Epoch: 24 [360/1260 (29%)]\tLoss: 0.025617\n",
      "Train Epoch: 24 [420/1260 (33%)]\tLoss: 0.004658\n",
      "Train Epoch: 24 [480/1260 (38%)]\tLoss: 0.000834\n",
      "Train Epoch: 24 [540/1260 (43%)]\tLoss: 0.021994\n",
      "Train Epoch: 24 [600/1260 (48%)]\tLoss: 0.032319\n",
      "Train Epoch: 24 [660/1260 (52%)]\tLoss: 0.001422\n",
      "Train Epoch: 24 [720/1260 (57%)]\tLoss: 0.023192\n",
      "Train Epoch: 24 [780/1260 (62%)]\tLoss: 0.141869\n",
      "Train Epoch: 24 [840/1260 (67%)]\tLoss: 0.187947\n",
      "Train Epoch: 24 [900/1260 (71%)]\tLoss: 0.253328\n",
      "Train Epoch: 24 [960/1260 (76%)]\tLoss: 0.036278\n",
      "Train Epoch: 24 [1020/1260 (81%)]\tLoss: 0.022353\n",
      "Train Epoch: 24 [1080/1260 (86%)]\tLoss: 0.166880\n",
      "Train Epoch: 24 [1140/1260 (90%)]\tLoss: 0.440968\n",
      "Train Epoch: 24 [1200/1260 (95%)]\tLoss: 0.002483\n",
      "Train Epoch: 25 [0/1260 (0%)]\tLoss: 0.001084\n",
      "Train Epoch: 25 [60/1260 (5%)]\tLoss: 0.024235\n",
      "Train Epoch: 25 [120/1260 (10%)]\tLoss: 0.026587\n",
      "Train Epoch: 25 [180/1260 (14%)]\tLoss: 0.028516\n",
      "Train Epoch: 25 [240/1260 (19%)]\tLoss: 0.004427\n",
      "Train Epoch: 25 [300/1260 (24%)]\tLoss: 0.006375\n",
      "Train Epoch: 25 [360/1260 (29%)]\tLoss: 0.037962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 25 [420/1260 (33%)]\tLoss: 0.018432\n",
      "Train Epoch: 25 [480/1260 (38%)]\tLoss: 0.001961\n",
      "Train Epoch: 25 [540/1260 (43%)]\tLoss: 0.015875\n",
      "Train Epoch: 25 [600/1260 (48%)]\tLoss: 0.523281\n",
      "Train Epoch: 25 [660/1260 (52%)]\tLoss: 0.015575\n",
      "Train Epoch: 25 [720/1260 (57%)]\tLoss: 0.008135\n",
      "Train Epoch: 25 [780/1260 (62%)]\tLoss: 0.017571\n",
      "Train Epoch: 25 [840/1260 (67%)]\tLoss: 0.020412\n",
      "Train Epoch: 25 [900/1260 (71%)]\tLoss: 0.037566\n",
      "Train Epoch: 25 [960/1260 (76%)]\tLoss: 0.008384\n",
      "Train Epoch: 25 [1020/1260 (81%)]\tLoss: 0.000570\n",
      "Train Epoch: 25 [1080/1260 (86%)]\tLoss: 0.000002\n",
      "Train Epoch: 25 [1140/1260 (90%)]\tLoss: 0.000573\n",
      "Train Epoch: 25 [1200/1260 (95%)]\tLoss: 0.028581\n",
      "Train Epoch: 26 [0/1260 (0%)]\tLoss: 0.004926\n",
      "Train Epoch: 26 [60/1260 (5%)]\tLoss: 0.495976\n",
      "Train Epoch: 26 [120/1260 (10%)]\tLoss: 0.004111\n",
      "Train Epoch: 26 [180/1260 (14%)]\tLoss: 0.002834\n",
      "Train Epoch: 26 [240/1260 (19%)]\tLoss: 0.000231\n",
      "Train Epoch: 26 [300/1260 (24%)]\tLoss: 0.000586\n",
      "Train Epoch: 26 [360/1260 (29%)]\tLoss: 0.000459\n",
      "Train Epoch: 26 [420/1260 (33%)]\tLoss: 0.040177\n",
      "Train Epoch: 26 [480/1260 (38%)]\tLoss: 0.003849\n",
      "Train Epoch: 26 [540/1260 (43%)]\tLoss: 0.028487\n",
      "Train Epoch: 26 [600/1260 (48%)]\tLoss: 0.155536\n",
      "Train Epoch: 26 [660/1260 (52%)]\tLoss: 0.055886\n",
      "Train Epoch: 26 [720/1260 (57%)]\tLoss: 0.000173\n",
      "Train Epoch: 26 [780/1260 (62%)]\tLoss: 0.012560\n",
      "Train Epoch: 26 [840/1260 (67%)]\tLoss: 0.008384\n",
      "Train Epoch: 26 [900/1260 (71%)]\tLoss: 0.009485\n",
      "Train Epoch: 26 [960/1260 (76%)]\tLoss: 0.000702\n",
      "Train Epoch: 26 [1020/1260 (81%)]\tLoss: 0.009028\n",
      "Train Epoch: 26 [1080/1260 (86%)]\tLoss: 0.002878\n",
      "Train Epoch: 26 [1140/1260 (90%)]\tLoss: 0.041097\n",
      "Train Epoch: 26 [1200/1260 (95%)]\tLoss: 0.002726\n",
      "Train Epoch: 27 [0/1260 (0%)]\tLoss: 0.012694\n",
      "Train Epoch: 27 [60/1260 (5%)]\tLoss: 0.000455\n",
      "Train Epoch: 27 [120/1260 (10%)]\tLoss: 0.011940\n",
      "Train Epoch: 27 [180/1260 (14%)]\tLoss: 0.028474\n",
      "Train Epoch: 27 [240/1260 (19%)]\tLoss: 0.000676\n",
      "Train Epoch: 27 [300/1260 (24%)]\tLoss: 0.029428\n",
      "Train Epoch: 27 [360/1260 (29%)]\tLoss: 0.003527\n",
      "Train Epoch: 27 [420/1260 (33%)]\tLoss: 0.000044\n",
      "Train Epoch: 27 [480/1260 (38%)]\tLoss: 0.022931\n",
      "Train Epoch: 27 [540/1260 (43%)]\tLoss: 0.001543\n",
      "Train Epoch: 27 [600/1260 (48%)]\tLoss: 0.001104\n",
      "Train Epoch: 27 [660/1260 (52%)]\tLoss: 0.009441\n",
      "Train Epoch: 27 [720/1260 (57%)]\tLoss: 0.007140\n",
      "Train Epoch: 27 [780/1260 (62%)]\tLoss: 0.004938\n",
      "Train Epoch: 27 [840/1260 (67%)]\tLoss: 0.000488\n",
      "Train Epoch: 27 [900/1260 (71%)]\tLoss: 0.000008\n",
      "Train Epoch: 27 [960/1260 (76%)]\tLoss: 0.295518\n",
      "Train Epoch: 27 [1020/1260 (81%)]\tLoss: 0.000913\n",
      "Train Epoch: 27 [1080/1260 (86%)]\tLoss: 0.003134\n",
      "Train Epoch: 27 [1140/1260 (90%)]\tLoss: 0.000547\n",
      "Train Epoch: 27 [1200/1260 (95%)]\tLoss: 0.099751\n",
      "Train Epoch: 28 [0/1260 (0%)]\tLoss: 0.000369\n",
      "Train Epoch: 28 [60/1260 (5%)]\tLoss: 0.000116\n",
      "Train Epoch: 28 [120/1260 (10%)]\tLoss: 0.010172\n",
      "Train Epoch: 28 [180/1260 (14%)]\tLoss: 0.015764\n",
      "Train Epoch: 28 [240/1260 (19%)]\tLoss: 0.012164\n",
      "Train Epoch: 28 [300/1260 (24%)]\tLoss: 0.052480\n",
      "Train Epoch: 28 [360/1260 (29%)]\tLoss: 0.012708\n",
      "Train Epoch: 28 [420/1260 (33%)]\tLoss: 0.036250\n",
      "Train Epoch: 28 [480/1260 (38%)]\tLoss: 0.033302\n",
      "Train Epoch: 28 [540/1260 (43%)]\tLoss: 0.015149\n",
      "Train Epoch: 28 [600/1260 (48%)]\tLoss: 0.043926\n",
      "Train Epoch: 28 [660/1260 (52%)]\tLoss: 0.584054\n",
      "Train Epoch: 28 [720/1260 (57%)]\tLoss: 0.003632\n",
      "Train Epoch: 28 [780/1260 (62%)]\tLoss: 0.000459\n",
      "Train Epoch: 28 [840/1260 (67%)]\tLoss: 0.002035\n",
      "Train Epoch: 28 [900/1260 (71%)]\tLoss: 0.001045\n",
      "Train Epoch: 28 [960/1260 (76%)]\tLoss: 0.052859\n",
      "Train Epoch: 28 [1020/1260 (81%)]\tLoss: 0.026319\n",
      "Train Epoch: 28 [1080/1260 (86%)]\tLoss: 0.000604\n",
      "Train Epoch: 28 [1140/1260 (90%)]\tLoss: 0.003560\n",
      "Train Epoch: 28 [1200/1260 (95%)]\tLoss: 0.015477\n",
      "Train Epoch: 29 [0/1260 (0%)]\tLoss: 0.037364\n",
      "Train Epoch: 29 [60/1260 (5%)]\tLoss: 0.000868\n",
      "Train Epoch: 29 [120/1260 (10%)]\tLoss: 0.014209\n",
      "Train Epoch: 29 [180/1260 (14%)]\tLoss: 0.018598\n",
      "Train Epoch: 29 [240/1260 (19%)]\tLoss: 0.001451\n",
      "Train Epoch: 29 [300/1260 (24%)]\tLoss: 0.011544\n",
      "Train Epoch: 29 [360/1260 (29%)]\tLoss: 0.041631\n",
      "Train Epoch: 29 [420/1260 (33%)]\tLoss: 0.095739\n",
      "Train Epoch: 29 [480/1260 (38%)]\tLoss: 0.008962\n",
      "Train Epoch: 29 [540/1260 (43%)]\tLoss: 0.007210\n",
      "Train Epoch: 29 [600/1260 (48%)]\tLoss: 0.007121\n",
      "Train Epoch: 29 [660/1260 (52%)]\tLoss: 0.968566\n",
      "Train Epoch: 29 [720/1260 (57%)]\tLoss: 0.044971\n",
      "Train Epoch: 29 [780/1260 (62%)]\tLoss: 0.002465\n",
      "Train Epoch: 29 [840/1260 (67%)]\tLoss: 0.169772\n",
      "Train Epoch: 29 [900/1260 (71%)]\tLoss: 0.029663\n",
      "Train Epoch: 29 [960/1260 (76%)]\tLoss: 0.040585\n",
      "Train Epoch: 29 [1020/1260 (81%)]\tLoss: 0.007723\n",
      "Train Epoch: 29 [1080/1260 (86%)]\tLoss: 0.004849\n",
      "Train Epoch: 29 [1140/1260 (90%)]\tLoss: 0.039712\n",
      "Train Epoch: 29 [1200/1260 (95%)]\tLoss: 0.023535\n",
      "Train Epoch: 30 [0/1260 (0%)]\tLoss: 0.001179\n",
      "Train Epoch: 30 [60/1260 (5%)]\tLoss: 0.002012\n",
      "Train Epoch: 30 [120/1260 (10%)]\tLoss: 0.128338\n",
      "Train Epoch: 30 [180/1260 (14%)]\tLoss: 0.016711\n",
      "Train Epoch: 30 [240/1260 (19%)]\tLoss: 0.031068\n",
      "Train Epoch: 30 [300/1260 (24%)]\tLoss: 0.002697\n",
      "Train Epoch: 30 [360/1260 (29%)]\tLoss: 0.041074\n",
      "Train Epoch: 30 [420/1260 (33%)]\tLoss: 0.000820\n",
      "Train Epoch: 30 [480/1260 (38%)]\tLoss: 0.004261\n",
      "Train Epoch: 30 [540/1260 (43%)]\tLoss: 0.000626\n",
      "Train Epoch: 30 [600/1260 (48%)]\tLoss: 0.003720\n",
      "Train Epoch: 30 [660/1260 (52%)]\tLoss: 0.000050\n",
      "Train Epoch: 30 [720/1260 (57%)]\tLoss: 0.002169\n",
      "Train Epoch: 30 [780/1260 (62%)]\tLoss: 0.000062\n",
      "Train Epoch: 30 [840/1260 (67%)]\tLoss: 0.003470\n",
      "Train Epoch: 30 [900/1260 (71%)]\tLoss: 0.018372\n",
      "Train Epoch: 30 [960/1260 (76%)]\tLoss: 0.000590\n",
      "Train Epoch: 30 [1020/1260 (81%)]\tLoss: 0.000685\n",
      "Train Epoch: 30 [1080/1260 (86%)]\tLoss: 0.002030\n",
      "Train Epoch: 30 [1140/1260 (90%)]\tLoss: 0.055787\n",
      "Train Epoch: 30 [1200/1260 (95%)]\tLoss: 0.003429\n",
      "Train Epoch: 31 [0/1260 (0%)]\tLoss: 0.027040\n",
      "Train Epoch: 31 [60/1260 (5%)]\tLoss: 0.009074\n",
      "Train Epoch: 31 [120/1260 (10%)]\tLoss: 0.018157\n",
      "Train Epoch: 31 [180/1260 (14%)]\tLoss: 0.031940\n",
      "Train Epoch: 31 [240/1260 (19%)]\tLoss: 0.002802\n",
      "Train Epoch: 31 [300/1260 (24%)]\tLoss: 0.030918\n",
      "Train Epoch: 31 [360/1260 (29%)]\tLoss: 0.000918\n",
      "Train Epoch: 31 [420/1260 (33%)]\tLoss: 0.000251\n",
      "Train Epoch: 31 [480/1260 (38%)]\tLoss: 0.003238\n",
      "Train Epoch: 31 [540/1260 (43%)]\tLoss: 0.002566\n",
      "Train Epoch: 31 [600/1260 (48%)]\tLoss: 0.000060\n",
      "Train Epoch: 31 [660/1260 (52%)]\tLoss: 0.000965\n",
      "Train Epoch: 31 [720/1260 (57%)]\tLoss: 0.009412\n",
      "Train Epoch: 31 [780/1260 (62%)]\tLoss: 0.019092\n",
      "Train Epoch: 31 [840/1260 (67%)]\tLoss: 0.000176\n",
      "Train Epoch: 31 [900/1260 (71%)]\tLoss: 0.018124\n",
      "Train Epoch: 31 [960/1260 (76%)]\tLoss: 0.004693\n",
      "Train Epoch: 31 [1020/1260 (81%)]\tLoss: 0.002470\n",
      "Train Epoch: 31 [1080/1260 (86%)]\tLoss: 0.001856\n",
      "Train Epoch: 31 [1140/1260 (90%)]\tLoss: 0.166076\n",
      "Train Epoch: 31 [1200/1260 (95%)]\tLoss: 0.005420\n",
      "Train Epoch: 32 [0/1260 (0%)]\tLoss: 0.001065\n",
      "Train Epoch: 32 [60/1260 (5%)]\tLoss: 0.039076\n",
      "Train Epoch: 32 [120/1260 (10%)]\tLoss: 0.000319\n",
      "Train Epoch: 32 [180/1260 (14%)]\tLoss: 0.185701\n",
      "Train Epoch: 32 [240/1260 (19%)]\tLoss: 0.000023\n",
      "Train Epoch: 32 [300/1260 (24%)]\tLoss: 0.000160\n",
      "Train Epoch: 32 [360/1260 (29%)]\tLoss: 0.013027\n",
      "Train Epoch: 32 [420/1260 (33%)]\tLoss: 0.000866\n",
      "Train Epoch: 32 [480/1260 (38%)]\tLoss: 0.120224\n",
      "Train Epoch: 32 [540/1260 (43%)]\tLoss: 0.011253\n",
      "Train Epoch: 32 [600/1260 (48%)]\tLoss: 0.000013\n",
      "Train Epoch: 32 [660/1260 (52%)]\tLoss: 0.003563\n",
      "Train Epoch: 32 [720/1260 (57%)]\tLoss: 0.009265\n",
      "Train Epoch: 32 [780/1260 (62%)]\tLoss: 0.002244\n",
      "Train Epoch: 32 [840/1260 (67%)]\tLoss: 0.000254\n",
      "Train Epoch: 32 [900/1260 (71%)]\tLoss: 0.000202\n",
      "Train Epoch: 32 [960/1260 (76%)]\tLoss: 0.028843\n",
      "Train Epoch: 32 [1020/1260 (81%)]\tLoss: 0.000851\n",
      "Train Epoch: 32 [1080/1260 (86%)]\tLoss: 0.014232\n",
      "Train Epoch: 32 [1140/1260 (90%)]\tLoss: 0.165822\n",
      "Train Epoch: 32 [1200/1260 (95%)]\tLoss: 0.000280\n",
      "Train Epoch: 33 [0/1260 (0%)]\tLoss: 0.004723\n",
      "Train Epoch: 33 [60/1260 (5%)]\tLoss: 0.000615\n",
      "Train Epoch: 33 [120/1260 (10%)]\tLoss: 0.002831\n",
      "Train Epoch: 33 [180/1260 (14%)]\tLoss: 0.007943\n",
      "Train Epoch: 33 [240/1260 (19%)]\tLoss: 0.011525\n",
      "Train Epoch: 33 [300/1260 (24%)]\tLoss: 0.000991\n",
      "Train Epoch: 33 [360/1260 (29%)]\tLoss: 0.002712\n",
      "Train Epoch: 33 [420/1260 (33%)]\tLoss: 0.018712\n",
      "Train Epoch: 33 [480/1260 (38%)]\tLoss: 0.000992\n",
      "Train Epoch: 33 [540/1260 (43%)]\tLoss: 0.007815\n",
      "Train Epoch: 33 [600/1260 (48%)]\tLoss: 0.116301\n",
      "Train Epoch: 33 [660/1260 (52%)]\tLoss: 0.000520\n",
      "Train Epoch: 33 [720/1260 (57%)]\tLoss: 0.000219\n",
      "Train Epoch: 33 [780/1260 (62%)]\tLoss: 0.004497\n",
      "Train Epoch: 33 [840/1260 (67%)]\tLoss: 0.011538\n",
      "Train Epoch: 33 [900/1260 (71%)]\tLoss: 0.013929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 33 [960/1260 (76%)]\tLoss: 0.021960\n",
      "Train Epoch: 33 [1020/1260 (81%)]\tLoss: 0.000702\n",
      "Train Epoch: 33 [1080/1260 (86%)]\tLoss: 0.006748\n",
      "Train Epoch: 33 [1140/1260 (90%)]\tLoss: 0.000776\n",
      "Train Epoch: 33 [1200/1260 (95%)]\tLoss: 0.164989\n",
      "Train Epoch: 34 [0/1260 (0%)]\tLoss: 0.001459\n",
      "Train Epoch: 34 [60/1260 (5%)]\tLoss: 0.018144\n",
      "Train Epoch: 34 [120/1260 (10%)]\tLoss: 0.026767\n",
      "Train Epoch: 34 [180/1260 (14%)]\tLoss: 0.016898\n",
      "Train Epoch: 34 [240/1260 (19%)]\tLoss: 0.141355\n",
      "Train Epoch: 34 [300/1260 (24%)]\tLoss: 0.000653\n",
      "Train Epoch: 34 [360/1260 (29%)]\tLoss: 0.055640\n",
      "Train Epoch: 34 [420/1260 (33%)]\tLoss: 0.032232\n",
      "Train Epoch: 34 [480/1260 (38%)]\tLoss: 0.000015\n",
      "Train Epoch: 34 [540/1260 (43%)]\tLoss: 0.001175\n",
      "Train Epoch: 34 [600/1260 (48%)]\tLoss: 0.044016\n",
      "Train Epoch: 34 [660/1260 (52%)]\tLoss: 0.732068\n",
      "Train Epoch: 34 [720/1260 (57%)]\tLoss: 0.005386\n",
      "Train Epoch: 34 [780/1260 (62%)]\tLoss: 0.003508\n",
      "Train Epoch: 34 [840/1260 (67%)]\tLoss: 0.427774\n",
      "Train Epoch: 34 [900/1260 (71%)]\tLoss: 0.019258\n",
      "Train Epoch: 34 [960/1260 (76%)]\tLoss: 0.003832\n",
      "Train Epoch: 34 [1020/1260 (81%)]\tLoss: 0.007418\n",
      "Train Epoch: 34 [1080/1260 (86%)]\tLoss: 0.005972\n",
      "Train Epoch: 34 [1140/1260 (90%)]\tLoss: 0.004046\n",
      "Train Epoch: 34 [1200/1260 (95%)]\tLoss: 0.023366\n",
      "Train Epoch: 35 [0/1260 (0%)]\tLoss: 0.006807\n",
      "Train Epoch: 35 [60/1260 (5%)]\tLoss: 0.002262\n",
      "Train Epoch: 35 [120/1260 (10%)]\tLoss: 0.011111\n",
      "Train Epoch: 35 [180/1260 (14%)]\tLoss: 0.000141\n",
      "Train Epoch: 35 [240/1260 (19%)]\tLoss: 0.006083\n",
      "Train Epoch: 35 [300/1260 (24%)]\tLoss: 0.002980\n",
      "Train Epoch: 35 [360/1260 (29%)]\tLoss: 0.020823\n",
      "Train Epoch: 35 [420/1260 (33%)]\tLoss: 0.000478\n",
      "Train Epoch: 35 [480/1260 (38%)]\tLoss: 0.002096\n",
      "Train Epoch: 35 [540/1260 (43%)]\tLoss: 0.704050\n",
      "Train Epoch: 35 [600/1260 (48%)]\tLoss: 0.150516\n",
      "Train Epoch: 35 [660/1260 (52%)]\tLoss: 0.007962\n",
      "Train Epoch: 35 [720/1260 (57%)]\tLoss: 0.033603\n",
      "Train Epoch: 35 [780/1260 (62%)]\tLoss: 0.001837\n",
      "Train Epoch: 35 [840/1260 (67%)]\tLoss: 0.000098\n",
      "Train Epoch: 35 [900/1260 (71%)]\tLoss: 0.036394\n",
      "Train Epoch: 35 [960/1260 (76%)]\tLoss: 0.014298\n",
      "Train Epoch: 35 [1020/1260 (81%)]\tLoss: 0.000837\n",
      "Train Epoch: 35 [1080/1260 (86%)]\tLoss: 0.000605\n",
      "Train Epoch: 35 [1140/1260 (90%)]\tLoss: 0.024151\n",
      "Train Epoch: 35 [1200/1260 (95%)]\tLoss: 0.012297\n",
      "Train Epoch: 36 [0/1260 (0%)]\tLoss: 0.022498\n",
      "Train Epoch: 36 [60/1260 (5%)]\tLoss: 0.000085\n",
      "Train Epoch: 36 [120/1260 (10%)]\tLoss: 0.011597\n",
      "Train Epoch: 36 [180/1260 (14%)]\tLoss: 0.023727\n",
      "Train Epoch: 36 [240/1260 (19%)]\tLoss: 0.007192\n",
      "Train Epoch: 36 [300/1260 (24%)]\tLoss: 0.005359\n",
      "Train Epoch: 36 [360/1260 (29%)]\tLoss: 0.024487\n",
      "Train Epoch: 36 [420/1260 (33%)]\tLoss: 0.007430\n",
      "Train Epoch: 36 [480/1260 (38%)]\tLoss: 0.002269\n",
      "Train Epoch: 36 [540/1260 (43%)]\tLoss: 0.000083\n",
      "Train Epoch: 36 [600/1260 (48%)]\tLoss: 0.686074\n",
      "Train Epoch: 36 [660/1260 (52%)]\tLoss: 0.002155\n",
      "Train Epoch: 36 [720/1260 (57%)]\tLoss: 0.018161\n",
      "Train Epoch: 36 [780/1260 (62%)]\tLoss: 0.035038\n",
      "Train Epoch: 36 [840/1260 (67%)]\tLoss: 0.000297\n",
      "Train Epoch: 36 [900/1260 (71%)]\tLoss: 0.019849\n",
      "Train Epoch: 36 [960/1260 (76%)]\tLoss: 0.000185\n",
      "Train Epoch: 36 [1020/1260 (81%)]\tLoss: 0.043962\n",
      "Train Epoch: 36 [1080/1260 (86%)]\tLoss: 0.017747\n",
      "Train Epoch: 36 [1140/1260 (90%)]\tLoss: 0.000213\n",
      "Train Epoch: 36 [1200/1260 (95%)]\tLoss: 0.003605\n",
      "Train Epoch: 37 [0/1260 (0%)]\tLoss: 0.000787\n",
      "Train Epoch: 37 [60/1260 (5%)]\tLoss: 0.031145\n",
      "Train Epoch: 37 [120/1260 (10%)]\tLoss: 0.020378\n",
      "Train Epoch: 37 [180/1260 (14%)]\tLoss: 0.007810\n",
      "Train Epoch: 37 [240/1260 (19%)]\tLoss: 0.178194\n",
      "Train Epoch: 37 [300/1260 (24%)]\tLoss: 0.015103\n",
      "Train Epoch: 37 [360/1260 (29%)]\tLoss: 0.000118\n",
      "Train Epoch: 37 [420/1260 (33%)]\tLoss: 0.000099\n",
      "Train Epoch: 37 [480/1260 (38%)]\tLoss: 0.018544\n",
      "Train Epoch: 37 [540/1260 (43%)]\tLoss: 0.006317\n",
      "Train Epoch: 37 [600/1260 (48%)]\tLoss: 0.004424\n",
      "Train Epoch: 37 [660/1260 (52%)]\tLoss: 0.006459\n",
      "Train Epoch: 37 [720/1260 (57%)]\tLoss: 0.002741\n",
      "Train Epoch: 37 [780/1260 (62%)]\tLoss: 0.022551\n",
      "Train Epoch: 37 [840/1260 (67%)]\tLoss: 0.013649\n",
      "Train Epoch: 37 [900/1260 (71%)]\tLoss: 0.007258\n",
      "Train Epoch: 37 [960/1260 (76%)]\tLoss: 0.003308\n",
      "Train Epoch: 37 [1020/1260 (81%)]\tLoss: 0.000000\n",
      "Train Epoch: 37 [1080/1260 (86%)]\tLoss: 0.008354\n",
      "Train Epoch: 37 [1140/1260 (90%)]\tLoss: 0.004227\n",
      "Train Epoch: 37 [1200/1260 (95%)]\tLoss: 0.002794\n",
      "Train Epoch: 38 [0/1260 (0%)]\tLoss: 0.000177\n",
      "Train Epoch: 38 [60/1260 (5%)]\tLoss: 0.001005\n",
      "Train Epoch: 38 [120/1260 (10%)]\tLoss: 0.000067\n",
      "Train Epoch: 38 [180/1260 (14%)]\tLoss: 0.320573\n",
      "Train Epoch: 38 [240/1260 (19%)]\tLoss: 0.019062\n",
      "Train Epoch: 38 [300/1260 (24%)]\tLoss: 0.010479\n",
      "Train Epoch: 38 [360/1260 (29%)]\tLoss: 0.012164\n",
      "Train Epoch: 38 [420/1260 (33%)]\tLoss: 0.110596\n",
      "Train Epoch: 38 [480/1260 (38%)]\tLoss: 0.002317\n",
      "Train Epoch: 38 [540/1260 (43%)]\tLoss: 0.001001\n",
      "Train Epoch: 38 [600/1260 (48%)]\tLoss: 0.013395\n",
      "Train Epoch: 38 [660/1260 (52%)]\tLoss: 0.004840\n",
      "Train Epoch: 38 [720/1260 (57%)]\tLoss: 0.000906\n",
      "Train Epoch: 38 [780/1260 (62%)]\tLoss: 0.002721\n",
      "Train Epoch: 38 [840/1260 (67%)]\tLoss: 0.000536\n",
      "Train Epoch: 38 [900/1260 (71%)]\tLoss: 0.343603\n",
      "Train Epoch: 38 [960/1260 (76%)]\tLoss: 0.010078\n",
      "Train Epoch: 38 [1020/1260 (81%)]\tLoss: 0.000023\n",
      "Train Epoch: 38 [1080/1260 (86%)]\tLoss: 0.021850\n",
      "Train Epoch: 38 [1140/1260 (90%)]\tLoss: 0.003064\n",
      "Train Epoch: 38 [1200/1260 (95%)]\tLoss: 0.018162\n",
      "Train Epoch: 39 [0/1260 (0%)]\tLoss: 0.000971\n",
      "Train Epoch: 39 [60/1260 (5%)]\tLoss: 0.020039\n",
      "Train Epoch: 39 [120/1260 (10%)]\tLoss: 0.005101\n",
      "Train Epoch: 39 [180/1260 (14%)]\tLoss: 0.015626\n",
      "Train Epoch: 39 [240/1260 (19%)]\tLoss: 0.005815\n",
      "Train Epoch: 39 [300/1260 (24%)]\tLoss: 0.000085\n",
      "Train Epoch: 39 [360/1260 (29%)]\tLoss: 0.017402\n",
      "Train Epoch: 39 [420/1260 (33%)]\tLoss: 0.050413\n",
      "Train Epoch: 39 [480/1260 (38%)]\tLoss: 0.000066\n",
      "Train Epoch: 39 [540/1260 (43%)]\tLoss: 0.000581\n",
      "Train Epoch: 39 [600/1260 (48%)]\tLoss: 0.002134\n",
      "Train Epoch: 39 [660/1260 (52%)]\tLoss: 0.002867\n",
      "Train Epoch: 39 [720/1260 (57%)]\tLoss: 0.191758\n",
      "Train Epoch: 39 [780/1260 (62%)]\tLoss: 0.009494\n",
      "Train Epoch: 39 [840/1260 (67%)]\tLoss: 0.012046\n",
      "Train Epoch: 39 [900/1260 (71%)]\tLoss: 0.011504\n",
      "Train Epoch: 39 [960/1260 (76%)]\tLoss: 0.023803\n",
      "Train Epoch: 39 [1020/1260 (81%)]\tLoss: 0.475179\n",
      "Train Epoch: 39 [1080/1260 (86%)]\tLoss: 0.011368\n",
      "Train Epoch: 39 [1140/1260 (90%)]\tLoss: 0.014967\n",
      "Train Epoch: 39 [1200/1260 (95%)]\tLoss: 0.024000\n",
      "Train Epoch: 40 [0/1260 (0%)]\tLoss: 0.000373\n",
      "Train Epoch: 40 [60/1260 (5%)]\tLoss: 0.003582\n",
      "Train Epoch: 40 [120/1260 (10%)]\tLoss: 0.001570\n",
      "Train Epoch: 40 [180/1260 (14%)]\tLoss: 0.044804\n",
      "Train Epoch: 40 [240/1260 (19%)]\tLoss: 1.660974\n",
      "Train Epoch: 40 [300/1260 (24%)]\tLoss: 0.025477\n",
      "Train Epoch: 40 [360/1260 (29%)]\tLoss: 0.008030\n",
      "Train Epoch: 40 [420/1260 (33%)]\tLoss: 0.028157\n",
      "Train Epoch: 40 [480/1260 (38%)]\tLoss: 0.018033\n",
      "Train Epoch: 40 [540/1260 (43%)]\tLoss: 0.574248\n",
      "Train Epoch: 40 [600/1260 (48%)]\tLoss: 0.003390\n",
      "Train Epoch: 40 [660/1260 (52%)]\tLoss: 0.001297\n",
      "Train Epoch: 40 [720/1260 (57%)]\tLoss: 0.000611\n",
      "Train Epoch: 40 [780/1260 (62%)]\tLoss: 0.022797\n",
      "Train Epoch: 40 [840/1260 (67%)]\tLoss: 0.037518\n",
      "Train Epoch: 40 [900/1260 (71%)]\tLoss: 0.006388\n",
      "Train Epoch: 40 [960/1260 (76%)]\tLoss: 0.004378\n",
      "Train Epoch: 40 [1020/1260 (81%)]\tLoss: 0.350670\n",
      "Train Epoch: 40 [1080/1260 (86%)]\tLoss: 0.017714\n",
      "Train Epoch: 40 [1140/1260 (90%)]\tLoss: 0.004188\n",
      "Train Epoch: 40 [1200/1260 (95%)]\tLoss: 0.000370\n",
      "Train Epoch: 41 [0/1260 (0%)]\tLoss: 0.021075\n",
      "Train Epoch: 41 [60/1260 (5%)]\tLoss: 0.025143\n",
      "Train Epoch: 41 [120/1260 (10%)]\tLoss: 0.000796\n",
      "Train Epoch: 41 [180/1260 (14%)]\tLoss: 0.162270\n",
      "Train Epoch: 41 [240/1260 (19%)]\tLoss: 0.020306\n",
      "Train Epoch: 41 [300/1260 (24%)]\tLoss: 0.000392\n",
      "Train Epoch: 41 [360/1260 (29%)]\tLoss: 0.035444\n",
      "Train Epoch: 41 [420/1260 (33%)]\tLoss: 0.011225\n",
      "Train Epoch: 41 [480/1260 (38%)]\tLoss: 0.021162\n",
      "Train Epoch: 41 [540/1260 (43%)]\tLoss: 0.000119\n",
      "Train Epoch: 41 [600/1260 (48%)]\tLoss: 0.002273\n",
      "Train Epoch: 41 [660/1260 (52%)]\tLoss: 0.000225\n",
      "Train Epoch: 41 [720/1260 (57%)]\tLoss: 0.004205\n",
      "Train Epoch: 41 [780/1260 (62%)]\tLoss: 0.000255\n",
      "Train Epoch: 41 [840/1260 (67%)]\tLoss: 0.100550\n",
      "Train Epoch: 41 [900/1260 (71%)]\tLoss: 0.018335\n",
      "Train Epoch: 41 [960/1260 (76%)]\tLoss: 0.013062\n",
      "Train Epoch: 41 [1020/1260 (81%)]\tLoss: 0.018808\n",
      "Train Epoch: 41 [1080/1260 (86%)]\tLoss: 0.016357\n",
      "Train Epoch: 41 [1140/1260 (90%)]\tLoss: 0.002541\n",
      "Train Epoch: 41 [1200/1260 (95%)]\tLoss: 0.006346\n",
      "Train Epoch: 42 [0/1260 (0%)]\tLoss: 0.030375\n",
      "Train Epoch: 42 [60/1260 (5%)]\tLoss: 0.014417\n",
      "Train Epoch: 42 [120/1260 (10%)]\tLoss: 0.002080\n",
      "Train Epoch: 42 [180/1260 (14%)]\tLoss: 0.045184\n",
      "Train Epoch: 42 [240/1260 (19%)]\tLoss: 0.008513\n",
      "Train Epoch: 42 [300/1260 (24%)]\tLoss: 0.018973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 42 [360/1260 (29%)]\tLoss: 0.008025\n",
      "Train Epoch: 42 [420/1260 (33%)]\tLoss: 0.052948\n",
      "Train Epoch: 42 [480/1260 (38%)]\tLoss: 0.000852\n",
      "Train Epoch: 42 [540/1260 (43%)]\tLoss: 0.000000\n",
      "Train Epoch: 42 [600/1260 (48%)]\tLoss: 0.001505\n",
      "Train Epoch: 42 [660/1260 (52%)]\tLoss: 0.018867\n",
      "Train Epoch: 42 [720/1260 (57%)]\tLoss: 0.000557\n",
      "Train Epoch: 42 [780/1260 (62%)]\tLoss: 0.000037\n",
      "Train Epoch: 42 [840/1260 (67%)]\tLoss: 0.007480\n",
      "Train Epoch: 42 [900/1260 (71%)]\tLoss: 0.000954\n",
      "Train Epoch: 42 [960/1260 (76%)]\tLoss: 0.017264\n",
      "Train Epoch: 42 [1020/1260 (81%)]\tLoss: 0.002338\n",
      "Train Epoch: 42 [1080/1260 (86%)]\tLoss: 0.020567\n",
      "Train Epoch: 42 [1140/1260 (90%)]\tLoss: 0.000064\n",
      "Train Epoch: 42 [1200/1260 (95%)]\tLoss: 0.011202\n",
      "Train Epoch: 43 [0/1260 (0%)]\tLoss: 0.023502\n",
      "Train Epoch: 43 [60/1260 (5%)]\tLoss: 0.034822\n",
      "Train Epoch: 43 [120/1260 (10%)]\tLoss: 0.002998\n",
      "Train Epoch: 43 [180/1260 (14%)]\tLoss: 0.009525\n",
      "Train Epoch: 43 [240/1260 (19%)]\tLoss: 0.014419\n",
      "Train Epoch: 43 [300/1260 (24%)]\tLoss: 0.003809\n",
      "Train Epoch: 43 [360/1260 (29%)]\tLoss: 0.000688\n",
      "Train Epoch: 43 [420/1260 (33%)]\tLoss: 0.018027\n",
      "Train Epoch: 43 [480/1260 (38%)]\tLoss: 0.008644\n",
      "Train Epoch: 43 [540/1260 (43%)]\tLoss: 0.000513\n",
      "Train Epoch: 43 [600/1260 (48%)]\tLoss: 0.012440\n",
      "Train Epoch: 43 [660/1260 (52%)]\tLoss: 0.017843\n",
      "Train Epoch: 43 [720/1260 (57%)]\tLoss: 0.163865\n",
      "Train Epoch: 43 [780/1260 (62%)]\tLoss: 0.013298\n",
      "Train Epoch: 43 [840/1260 (67%)]\tLoss: 0.000021\n",
      "Train Epoch: 43 [900/1260 (71%)]\tLoss: 0.010423\n",
      "Train Epoch: 43 [960/1260 (76%)]\tLoss: 0.017687\n",
      "Train Epoch: 43 [1020/1260 (81%)]\tLoss: 0.014143\n",
      "Train Epoch: 43 [1080/1260 (86%)]\tLoss: 0.000837\n",
      "Train Epoch: 43 [1140/1260 (90%)]\tLoss: 0.000122\n",
      "Train Epoch: 43 [1200/1260 (95%)]\tLoss: 0.015738\n",
      "Train Epoch: 44 [0/1260 (0%)]\tLoss: 0.027882\n",
      "Train Epoch: 44 [60/1260 (5%)]\tLoss: 0.039105\n",
      "Train Epoch: 44 [120/1260 (10%)]\tLoss: 0.019635\n",
      "Train Epoch: 44 [180/1260 (14%)]\tLoss: 0.006538\n",
      "Train Epoch: 44 [240/1260 (19%)]\tLoss: 0.010642\n",
      "Train Epoch: 44 [300/1260 (24%)]\tLoss: 0.043709\n",
      "Train Epoch: 44 [360/1260 (29%)]\tLoss: 0.004535\n",
      "Train Epoch: 44 [420/1260 (33%)]\tLoss: 0.002128\n",
      "Train Epoch: 44 [480/1260 (38%)]\tLoss: 0.016105\n",
      "Train Epoch: 44 [540/1260 (43%)]\tLoss: 0.002576\n",
      "Train Epoch: 44 [600/1260 (48%)]\tLoss: 0.034600\n",
      "Train Epoch: 44 [660/1260 (52%)]\tLoss: 0.022999\n",
      "Train Epoch: 44 [720/1260 (57%)]\tLoss: 0.023946\n",
      "Train Epoch: 44 [780/1260 (62%)]\tLoss: 0.014041\n",
      "Train Epoch: 44 [840/1260 (67%)]\tLoss: 0.006146\n",
      "Train Epoch: 44 [900/1260 (71%)]\tLoss: 0.000013\n",
      "Train Epoch: 44 [960/1260 (76%)]\tLoss: 0.008439\n",
      "Train Epoch: 44 [1020/1260 (81%)]\tLoss: 0.020515\n",
      "Train Epoch: 44 [1080/1260 (86%)]\tLoss: 0.478689\n",
      "Train Epoch: 44 [1140/1260 (90%)]\tLoss: 0.164814\n",
      "Train Epoch: 44 [1200/1260 (95%)]\tLoss: 0.013563\n",
      "Train Epoch: 45 [0/1260 (0%)]\tLoss: 0.007196\n",
      "Train Epoch: 45 [60/1260 (5%)]\tLoss: 0.003030\n",
      "Train Epoch: 45 [120/1260 (10%)]\tLoss: 0.000033\n",
      "Train Epoch: 45 [180/1260 (14%)]\tLoss: 0.028859\n",
      "Train Epoch: 45 [240/1260 (19%)]\tLoss: 0.001233\n",
      "Train Epoch: 45 [300/1260 (24%)]\tLoss: 0.011536\n",
      "Train Epoch: 45 [360/1260 (29%)]\tLoss: 0.017025\n",
      "Train Epoch: 45 [420/1260 (33%)]\tLoss: 0.044726\n",
      "Train Epoch: 45 [480/1260 (38%)]\tLoss: 0.026651\n",
      "Train Epoch: 45 [540/1260 (43%)]\tLoss: 0.017010\n",
      "Train Epoch: 45 [600/1260 (48%)]\tLoss: 0.002859\n",
      "Train Epoch: 45 [660/1260 (52%)]\tLoss: 0.005477\n",
      "Train Epoch: 45 [720/1260 (57%)]\tLoss: 0.022567\n",
      "Train Epoch: 45 [780/1260 (62%)]\tLoss: 0.170513\n",
      "Train Epoch: 45 [840/1260 (67%)]\tLoss: 0.000820\n",
      "Train Epoch: 45 [900/1260 (71%)]\tLoss: 0.005803\n",
      "Train Epoch: 45 [960/1260 (76%)]\tLoss: 0.004775\n",
      "Train Epoch: 45 [1020/1260 (81%)]\tLoss: 0.013968\n",
      "Train Epoch: 45 [1080/1260 (86%)]\tLoss: 0.001391\n",
      "Train Epoch: 45 [1140/1260 (90%)]\tLoss: 0.010304\n",
      "Train Epoch: 45 [1200/1260 (95%)]\tLoss: 0.005625\n",
      "Train Epoch: 46 [0/1260 (0%)]\tLoss: 0.001818\n",
      "Train Epoch: 46 [60/1260 (5%)]\tLoss: 0.020417\n",
      "Train Epoch: 46 [120/1260 (10%)]\tLoss: 0.004274\n",
      "Train Epoch: 46 [180/1260 (14%)]\tLoss: 0.259667\n",
      "Train Epoch: 46 [240/1260 (19%)]\tLoss: 0.000944\n",
      "Train Epoch: 46 [300/1260 (24%)]\tLoss: 0.013171\n",
      "Train Epoch: 46 [360/1260 (29%)]\tLoss: 0.005412\n",
      "Train Epoch: 46 [420/1260 (33%)]\tLoss: 0.000474\n",
      "Train Epoch: 46 [480/1260 (38%)]\tLoss: 0.051047\n",
      "Train Epoch: 46 [540/1260 (43%)]\tLoss: 0.110972\n",
      "Train Epoch: 46 [600/1260 (48%)]\tLoss: 0.011241\n",
      "Train Epoch: 46 [660/1260 (52%)]\tLoss: 0.452578\n",
      "Train Epoch: 46 [720/1260 (57%)]\tLoss: 0.018287\n",
      "Train Epoch: 46 [780/1260 (62%)]\tLoss: 0.035642\n",
      "Train Epoch: 46 [840/1260 (67%)]\tLoss: 0.007789\n",
      "Train Epoch: 46 [900/1260 (71%)]\tLoss: 0.000000\n",
      "Train Epoch: 46 [960/1260 (76%)]\tLoss: 0.013998\n",
      "Train Epoch: 46 [1020/1260 (81%)]\tLoss: 0.004315\n",
      "Train Epoch: 46 [1080/1260 (86%)]\tLoss: 0.000001\n",
      "Train Epoch: 46 [1140/1260 (90%)]\tLoss: 0.000001\n",
      "Train Epoch: 46 [1200/1260 (95%)]\tLoss: 0.009617\n",
      "Train Epoch: 47 [0/1260 (0%)]\tLoss: 0.000333\n",
      "Train Epoch: 47 [60/1260 (5%)]\tLoss: 0.001538\n",
      "Train Epoch: 47 [120/1260 (10%)]\tLoss: 0.000194\n",
      "Train Epoch: 47 [180/1260 (14%)]\tLoss: 0.000706\n",
      "Train Epoch: 47 [240/1260 (19%)]\tLoss: 0.001078\n",
      "Train Epoch: 47 [300/1260 (24%)]\tLoss: 0.004976\n",
      "Train Epoch: 47 [360/1260 (29%)]\tLoss: 0.011189\n",
      "Train Epoch: 47 [420/1260 (33%)]\tLoss: 0.001628\n",
      "Train Epoch: 47 [480/1260 (38%)]\tLoss: 0.024783\n",
      "Train Epoch: 47 [540/1260 (43%)]\tLoss: 0.008406\n",
      "Train Epoch: 47 [600/1260 (48%)]\tLoss: 0.000227\n",
      "Train Epoch: 47 [660/1260 (52%)]\tLoss: 0.009325\n",
      "Train Epoch: 47 [720/1260 (57%)]\tLoss: 0.003759\n",
      "Train Epoch: 47 [780/1260 (62%)]\tLoss: 0.004096\n",
      "Train Epoch: 47 [840/1260 (67%)]\tLoss: 0.000716\n",
      "Train Epoch: 47 [900/1260 (71%)]\tLoss: 0.001032\n",
      "Train Epoch: 47 [960/1260 (76%)]\tLoss: 0.555640\n",
      "Train Epoch: 47 [1020/1260 (81%)]\tLoss: 0.008233\n",
      "Train Epoch: 47 [1080/1260 (86%)]\tLoss: 0.000997\n",
      "Train Epoch: 47 [1140/1260 (90%)]\tLoss: 0.005303\n",
      "Train Epoch: 47 [1200/1260 (95%)]\tLoss: 0.005794\n",
      "Train Epoch: 48 [0/1260 (0%)]\tLoss: 0.000785\n",
      "Train Epoch: 48 [60/1260 (5%)]\tLoss: 0.001422\n",
      "Train Epoch: 48 [120/1260 (10%)]\tLoss: 0.000822\n",
      "Train Epoch: 48 [180/1260 (14%)]\tLoss: 0.016429\n",
      "Train Epoch: 48 [240/1260 (19%)]\tLoss: 0.000008\n",
      "Train Epoch: 48 [300/1260 (24%)]\tLoss: 0.025345\n",
      "Train Epoch: 48 [360/1260 (29%)]\tLoss: 0.173646\n",
      "Train Epoch: 48 [420/1260 (33%)]\tLoss: 0.000633\n",
      "Train Epoch: 48 [480/1260 (38%)]\tLoss: 0.021265\n",
      "Train Epoch: 48 [540/1260 (43%)]\tLoss: 0.007125\n",
      "Train Epoch: 48 [600/1260 (48%)]\tLoss: 0.000773\n",
      "Train Epoch: 48 [660/1260 (52%)]\tLoss: 0.031909\n",
      "Train Epoch: 48 [720/1260 (57%)]\tLoss: 0.000177\n",
      "Train Epoch: 48 [780/1260 (62%)]\tLoss: 0.147265\n",
      "Train Epoch: 48 [840/1260 (67%)]\tLoss: 0.000000\n",
      "Train Epoch: 48 [900/1260 (71%)]\tLoss: 0.000060\n",
      "Train Epoch: 48 [960/1260 (76%)]\tLoss: 0.732517\n",
      "Train Epoch: 48 [1020/1260 (81%)]\tLoss: 0.000001\n",
      "Train Epoch: 48 [1080/1260 (86%)]\tLoss: 0.014912\n",
      "Train Epoch: 48 [1140/1260 (90%)]\tLoss: 0.019538\n",
      "Train Epoch: 48 [1200/1260 (95%)]\tLoss: 0.012491\n",
      "Train Epoch: 49 [0/1260 (0%)]\tLoss: 0.007939\n",
      "Train Epoch: 49 [60/1260 (5%)]\tLoss: 0.003090\n",
      "Train Epoch: 49 [120/1260 (10%)]\tLoss: 0.015817\n",
      "Train Epoch: 49 [180/1260 (14%)]\tLoss: 0.002618\n",
      "Train Epoch: 49 [240/1260 (19%)]\tLoss: 0.011764\n",
      "Train Epoch: 49 [300/1260 (24%)]\tLoss: 0.006052\n",
      "Train Epoch: 49 [360/1260 (29%)]\tLoss: 0.000007\n",
      "Train Epoch: 49 [420/1260 (33%)]\tLoss: 0.000223\n",
      "Train Epoch: 49 [480/1260 (38%)]\tLoss: 0.000049\n",
      "Train Epoch: 49 [540/1260 (43%)]\tLoss: 0.004095\n",
      "Train Epoch: 49 [600/1260 (48%)]\tLoss: 0.000657\n",
      "Train Epoch: 49 [660/1260 (52%)]\tLoss: 0.000042\n",
      "Train Epoch: 49 [720/1260 (57%)]\tLoss: 0.013019\n",
      "Train Epoch: 49 [780/1260 (62%)]\tLoss: 0.806725\n",
      "Train Epoch: 49 [840/1260 (67%)]\tLoss: 0.009114\n",
      "Train Epoch: 49 [900/1260 (71%)]\tLoss: 0.000006\n",
      "Train Epoch: 49 [960/1260 (76%)]\tLoss: 0.001024\n",
      "Train Epoch: 49 [1020/1260 (81%)]\tLoss: 0.011376\n",
      "Train Epoch: 49 [1080/1260 (86%)]\tLoss: 0.000605\n",
      "Train Epoch: 49 [1140/1260 (90%)]\tLoss: 0.011092\n",
      "Train Epoch: 49 [1200/1260 (95%)]\tLoss: 0.028908\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "\n",
    "def train(epoch):\n",
    "  for _ in range(epoch):\n",
    "      network.train()\n",
    "      for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        #if batch_idx>1920 and batch_idx<1920+320: continue\n",
    "        optimizer.zero_grad()\n",
    "        data = data.unsqueeze(1)\n",
    "        #print(data.shape)\n",
    "        #print(data)\n",
    "        output = network(data)\n",
    "        #print(target.shape, target, output)\n",
    "        #assert 1==0\n",
    "        #loss = F.binary_cross_entropy_with_logits(output, target)\n",
    "        ##\n",
    "        #print(\"output:\")\n",
    "        #print(output)\n",
    "        #print(\"target:\")\n",
    "        #print(target)\n",
    "        #print(target.shape)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        '''\n",
    "        print(torch.isnan(data).sum(), (target==1).sum()+(target==0).sum())\n",
    "        assert (target==1).sum()+(target==0).sum()==16\n",
    "        print(torch.isnan(data).sum(), target.shape, target, output)\n",
    "        if torch.isnan(output).sum()!=0:\n",
    "            print(data, target, torch.isnan(data).sum())\n",
    "            print(data[-5])\n",
    "        assert torch.isnan(output).sum()==0\n",
    "        assert torch.isnan(loss).sum()==0\n",
    "        '''\n",
    "        if batch_idx % log_interval == 0:\n",
    "          #print(torch.isnan(data).sum(), target.shape, target, output)\n",
    "          print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            _ , batch_idx * len(data), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader), loss.item()))\n",
    "          train_losses.append(loss.item())\n",
    "          train_counter.append(\n",
    "            (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "          torch.save(network.state_dict(), './model.pth')\n",
    "          torch.save(optimizer.state_dict(), './optimizer.pth')\n",
    "          #print(network.state_dict())\n",
    "    \n",
    "train(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8489cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(list(range(len(train_losses))), train_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9b6ec861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor p in network.parameters():\\n    print(p)\\n    break\\ntmp = torch.load('./model.pth')\\nnetwork.load_state_dict(tmp)\\nfor p in network.parameters():\\n    print(p)\\n    break\\n\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for p in network.parameters():\n",
    "    print(p)\n",
    "    break\n",
    "tmp = torch.load('./model.pth')\n",
    "network.load_state_dict(tmp)\n",
    "for p in network.parameters():\n",
    "    print(p)\n",
    "    break\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8ef4e3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0067, Accuracy: 539/540 (99.81%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PCI\\anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as io\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]\n",
    "def test():\n",
    "  network.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      data = data.unsqueeze(1)\n",
    "      #print(\"data:\")\n",
    "      #print(data.shape)\n",
    "      output = network(data)\n",
    "      #print(\"output:\")\n",
    "      #print(output.shape)\n",
    "      \n",
    "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "      #print(output)\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      #print(pred)###\n",
    "      result1 = np.array(pred)\n",
    "      np.savetxt('pred.txt',result1)\n",
    "      result2 = np.array(target)\n",
    "      np.savetxt('target.txt',result2)\n",
    "      \n",
    "      #Save done\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "      \n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  test_losses.append(test_loss)\n",
    "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc55d6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport scipy.io as io\\nresult1 = np.array(result1)\\nnp.savetxt('npresult1.txt',result1)\\n\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import scipy.io as io\n",
    "result1 = np.array(result1)\n",
    "np.savetxt('npresult1.txt',result1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c01e565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor epoch in range(1, n_epochs + 1):\\n  train(epoch)\\n  test()\\nimport matplotlib.pyplot as plt\\nfig = plt.figure()\\nplt.plot(train_counter, train_losses, color='blue')\\nplt.scatter(test_counter, test_losses, color='red')\\nplt.legend(['Train Loss', 'Test Loss'], loc='upper right')\\nplt.xlabel('number of training examples seen')\\nplt.ylabel('negative log likelihood loss')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  train(epoch)\n",
    "  test()\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "plt.plot(train_counter, train_losses, color='blue')\n",
    "plt.scatter(test_counter, test_losses, color='red')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f43b9c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "762368ab",
   "metadata": {},
   "source": [
    "# confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ecea163d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0067, Accuracy: 539/540 (100%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "  import scipy.io as io\n",
    "  test_losses = []\n",
    "  test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]\n",
    "  network.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      data = data.unsqueeze(1)\n",
    "      #print(\"data:\")\n",
    "      #print(data.shape)\n",
    "      output = network(data)\n",
    "      #print(\"output:\")\n",
    "      #print(output.shape)\n",
    "      \n",
    "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "      #print(output)\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      #print(pred)###\n",
    "      result1 = np.array(pred)\n",
    "      #np.savetxt('pred.txt',result1)\n",
    "      result2 = np.array(target)\n",
    "      #np.savetxt('target.txt',result2)\n",
    "      \n",
    "      #Save done\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "      \n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  test_losses.append(test_loss)\n",
    "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cc519068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9981481338590575\n",
      "0.9981481338590575\n",
      "\n",
      "[0.99722992 0.99721448 1.        ]\n",
      "Acute       Normal      Chronic\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    " \n",
    "y_true = target\n",
    "y_pred = pred\n",
    " \n",
    "print(f1_score(y_true, y_pred, average='weighted'))# unbalance F1\n",
    "print(f1_score(y_true, y_pred, average='macro'))\n",
    "print()\n",
    "print(f1_score(y_true, y_pred, average=None))\n",
    "print(\"Acute       Normal      Chronic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "31b1d863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100.     0.     0.  ]\n",
      " [  0.56  99.44   0.  ]\n",
      " [  0.     0.   100.  ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set()\n",
    "f,ax = plt.subplots()\n",
    "y_true =(target)\n",
    "y_pred = (pred)\n",
    "C2 = confusion_matrix(y_true,y_pred,labels=[0,1,2])\n",
    "\n",
    "fm=C2.sum(axis=1)\n",
    "C3=C2/fm*100\n",
    "C3=np.around(C3,decimals=2)\n",
    "\n",
    "print(C3)\n",
    "a=sns.heatmap(C3,annot=True,ax=ax, cmap = 'Blues', fmt='g') #画热力图  , cbar = None\n",
    "\n",
    "ax.set_title('Confusion Matrix-Rat 19') #标题\n",
    "ax.set_xlabel('Predict') #x 轴\n",
    "ax.set_ylabel('True') #y 轴\n",
    "\n",
    "\n",
    "#Normal, Acute, Chronic, Pre-seizure\n",
    "a.set_xticklabels(['Acute','Normal','Chronic'])\n",
    "a.set_yticklabels(['Acute','Normal','Chronic'])\n",
    "\n",
    "\n",
    "fig = a.get_figure()\n",
    "fig.savefig(\"6F_3C.png\", dpi=1080)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
